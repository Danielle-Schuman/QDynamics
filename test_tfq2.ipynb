{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n",
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=41>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=110>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=235>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=153>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n",
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "thal (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fbs (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "restecg (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exang (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "slope (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ca (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "string_lookup_1 (StringLookup)  (None, 1)            0           thal[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "trestbps (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chol (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "thalach (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "oldpeak (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_7 (CategoryEn (None, 2)            1           sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_8 (CategoryEn (None, 5)            1           cp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_9 (CategoryEn (None, 2)            1           fbs[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_10 (CategoryE (None, 3)            1           restecg[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_11 (CategoryE (None, 2)            1           exang[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "normalization_11 (Normalization (None, 1)            3           slope[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_12 (CategoryE (None, 4)            1           ca[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_13 (CategoryE (None, 7)            1           string_lookup_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "normalization_6 (Normalization) (None, 1)            3           age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "normalization_7 (Normalization) (None, 1)            3           trestbps[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "normalization_8 (Normalization) (None, 1)            3           chol[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "normalization_9 (Normalization) (None, 1)            3           thalach[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization_10 (Normalization (None, 1)            3           oldpeak[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 31)           0           category_encoding_7[0][0]        \n",
      "                                                                 category_encoding_8[0][0]        \n",
      "                                                                 category_encoding_9[0][0]        \n",
      "                                                                 category_encoding_10[0][0]       \n",
      "                                                                 category_encoding_11[0][0]       \n",
      "                                                                 normalization_11[0][0]           \n",
      "                                                                 category_encoding_12[0][0]       \n",
      "                                                                 category_encoding_13[0][0]       \n",
      "                                                                 normalization_6[0][0]            \n",
      "                                                                 normalization_7[0][0]            \n",
      "                                                                 normalization_8[0][0]            \n",
      "                                                                 normalization_9[0][0]            \n",
      "                                                                 normalization_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1024        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "split_backprop_q_1 (SplitBackpr (None, 1)            4           input_2[0][0]                    \n",
      "                                                                 dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,185\n",
      "Trainable params: 1,160\n",
      "Non-trainable params: 25\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value ({'age': <tf.Tensor: shape=(), dtype=int64, numpy=47>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=130>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=253>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=179>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}) with an unsupported type (<class 'dict'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ed189f8f4f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1380\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value ({'age': <tf.Tensor: shape=(), dtype=int64, numpy=47>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=130>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=253>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=179>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}) with an unsupported type (<class 'dict'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from: https://github.com/keras-team/keras-io/blob/master/examples/structured_data/structured_data_classification_from_scratch.py\n",
    "Title: Structured data classification from scratch\n",
    "Author: [fchollet](https://twitter.com/fchollet)\n",
    "Date created: 2020/06/09\n",
    "Last modified: 2020/06/09\n",
    "Description: Binary classification of structured data including numerical and categorical features.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "## Introduction\n",
    "This example demonstrates how to do structured data classification, starting from a raw\n",
    "CSV file. Our data includes both numerical and categorical features. We will use Keras\n",
    "preprocessing layers to normalize the numerical features and vectorize the categorical\n",
    "ones.\n",
    "Note that this example should be run with TensorFlow 2.3 or higher, or `tf-nightly`.\n",
    "### The dataset\n",
    "[Our dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) is provided by the\n",
    "Cleveland Clinic Foundation for Heart Disease.\n",
    "It's a CSV file with 303 rows. Each row contains information about a patient (a\n",
    "**sample**), and each column describes an attribute of the patient (a **feature**). We\n",
    "use the features to predict whether a patient has a heart disease (**binary\n",
    "classification**).\n",
    "Here's the description of each feature:\n",
    "Column| Description| Feature Type\n",
    "------------|--------------------|----------------------\n",
    "Age | Age in years | Numerical\n",
    "Sex | (1 = male; 0 = female) | Categorical\n",
    "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
    "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
    "Chol | Serum cholesterol in mg/dl | Numerical\n",
    "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
    "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
    "Thalach | Maximum heart rate achieved | Numerical\n",
    "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
    "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
    "Slope | Slope of the peak exercise ST segment | Numerical\n",
    "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
    "Thal | 3 = normal; 6 = fixed defect; 7 = reversible defect | Categorical\n",
    "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Setup\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Preparing the data\n",
    "Let's download the data and load it into a Pandas dataframe:\n",
    "\"\"\"\n",
    "\n",
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)\n",
    "\n",
    "\"\"\"\n",
    "The dataset includes 303 samples with 14 columns per sample (13 features, plus the target\n",
    "label):\n",
    "\"\"\"\n",
    "\n",
    "dataframe.shape\n",
    "\n",
    "\"\"\"\n",
    "Here's a preview of a few samples:\n",
    "\"\"\"\n",
    "\n",
    "dataframe.head()\n",
    "\n",
    "\"\"\"\n",
    "The last column, \"target\", indicates whether the patient has a heart disease (1) or not\n",
    "(0).\n",
    "Let's split the data into a training and validation set:\n",
    "\"\"\"\n",
    "\n",
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Let's generate `tf.data.Dataset` objects for each dataframe:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "\"\"\"\n",
    "Each `Dataset` yields a tuple `(input, target)` where `input` is a dictionary of features\n",
    "and `target` is the value `0` or `1`:\n",
    "\"\"\"\n",
    "\n",
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)\n",
    "\n",
    "\"\"\"\n",
    "Let's batch the datasets:\n",
    "\"\"\"\n",
    "\n",
    "#train_ds = train_ds.batch(32)\n",
    "#val_ds = val_ds.batch(32)\n",
    "\n",
    "\"\"\"\n",
    "## Feature preprocessing with Keras layers\n",
    "The following features are categorical features encoded as integers:\n",
    "- `sex`\n",
    "- `cp`\n",
    "- `fbs`\n",
    "- `restecg`\n",
    "- `exang`\n",
    "- `ca`\n",
    "We will encode these features using **one-hot encoding** using the `CategoryEncoding()`\n",
    "layer.\n",
    "We also have a categorical feature encoded as a string: `thal`. We will first create an\n",
    "index of all possible features using the `StringLookup()` layer, then we will one-hot\n",
    "encode the output indices using a `CategoryEncoding()` layer.\n",
    "Finally, the following feature are continuous numerical features:\n",
    "- `age`\n",
    "- `trestbps`\n",
    "- `chol`\n",
    "- `thalach`\n",
    "- `oldpeak`\n",
    "- `slope`\n",
    "For each of these features, we will use a `Normalization()` layer to make sure the mean\n",
    "of each feature is 0 and its standard deviation is 1.\n",
    "Below, we define 3 utility functions to do the operations:\n",
    "- `encode_numerical_feature` to apply featurewise normalization to numerical features.\n",
    "- `encode_string_categorical_feature` to first turn string inputs into integer indices,\n",
    "then one-hot encode these integer indices.\n",
    "- `encode_integer_categorical_feature` to one-hot encode integer categorical features.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_string_categorical_feature(feature, name, dataset):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    index = StringLookup()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = index(feature)\n",
    "\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a dataset of indices\n",
    "    feature_ds = feature_ds.map(index)\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(encoded_feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_integer_categorical_feature(feature, name, dataset):\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "    encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Build a model\n",
    "With this done, we can create our end-to-end model:\n",
    "\"\"\"\n",
    "\n",
    "# Categorical features encoded as integers\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_integer_categorical_feature(sex, \"sex\", train_ds)\n",
    "cp_encoded = encode_integer_categorical_feature(cp, \"cp\", train_ds)\n",
    "fbs_encoded = encode_integer_categorical_feature(fbs, \"fbs\", train_ds)\n",
    "restecg_encoded = encode_integer_categorical_feature(restecg, \"restecg\", train_ds)\n",
    "exang_encoded = encode_integer_categorical_feature(exang, \"exang\", train_ds)\n",
    "ca_encoded = encode_integer_categorical_feature(ca, \"ca\", train_ds)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_string_categorical_feature(thal, \"thal\", train_ds)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# TFQ / Cirq code for quantum layer: 1 node, input-vector-length = 4 (TODO: make 16)\n",
    "import tensorflow_quantum as tfq\n",
    "import cirq\n",
    "from cirq import H, X, cphase, CNOT, Z, T\n",
    "from cirq.circuits import InsertStrategy\n",
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "\n",
    "# adapted from https://github.com/ghellstern/QuantumNN/blob/master/Multi-QBit-Classifier%20TF%20NN-Encoding_Github.ipynb\n",
    "class SplitBackpropQ(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, upstream_symbols, managed_symbols, managed_init_vals,\n",
    "                 operators):\n",
    "        \"\"\"Create a layer that splits backprop between several variables.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            upstream_symbols: Python iterable of symbols to bakcprop\n",
    "                through this layer.\n",
    "            managed_symbols: Python iterable of symbols to backprop\n",
    "                into variables managed by this layer.\n",
    "            managed_init_vals: Python iterable of initial values\n",
    "                for managed_symbols.\n",
    "            operators: Python iterable of operators to use for expectation.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(SplitBackpropQ)\n",
    "        self.all_symbols = upstream_symbols + managed_symbols\n",
    "        self.upstream_symbols = upstream_symbols\n",
    "        self.managed_symbols = managed_symbols\n",
    "        self.managed_init = managed_init_vals\n",
    "        self.ops = operators\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.managed_weights = self.add_weight(\n",
    "            shape=(1, len(self.managed_symbols)),\n",
    "            initializer=tf.constant_initializer(self.managed_init))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs are: circuit tensor, upstream values\n",
    "        upstream_shape = tf.gather(tf.shape(inputs[0]), 0)\n",
    "        tiled_up_weights = tf.tile(self.managed_weights, [upstream_shape, 1])\n",
    "        joined_params = tf.concat([inputs[1], tiled_up_weights], 1)\n",
    "        return tfq.layers.Expectation()(inputs[0],\n",
    "                                        operators=measurement,\n",
    "                                        symbol_names=self.all_symbols,\n",
    "                                        symbol_values=joined_params)\n",
    "\n",
    "\n",
    "# TODO: Normalize weights and inputs to be between [0, pi / 2]\n",
    "# TODO: replace CPhase-Gate with Multi-controlled Phase gate and use 4 qubits, Input-Size 16 instead\n",
    "# 2 regular qubits, 1 ancilla\n",
    "number_qubits = 3\n",
    "number_regular_qubits = number_qubits - 1\n",
    "\n",
    "# specify parameters to set later with NN inputs and weights using Keras + TFQ\n",
    "regular_qubits = [cirq.GridQubit(i, 0) for i in range(number_regular_qubits)]\n",
    "ancilla = cirq.GridQubit(number_regular_qubits, 0)\n",
    "control_params = sympy.symbols('i0, i1, i2, i3')\n",
    "control_params1 = sympy.symbols('w0, w1, w2, w3')\n",
    "\n",
    "# specify cirq circuit\n",
    "qc = cirq.Circuit()\n",
    "size = len(regular_qubits) ** 2\n",
    "# subtract first input from other inputs to save gates\n",
    "#inputs = []\n",
    "#for i in range(1, size):\n",
    "    #inputs.append(control_params[i] - control_params[0])\n",
    "# do the same for weights\n",
    "#weights = []\n",
    "#for i in range(1, size):\n",
    "    #weights.append(control_params1[i] - control_params1[0])\n",
    "# apply Hadamard gate to all regular qubits to create a superposition\n",
    "qc.append(H.on_each(*regular_qubits))\n",
    "# loop over all inputs in inputvector to encode them to the right base states using phase-shifts\n",
    "for index in range(size):\n",
    "    insert_list = []\n",
    "    # index as binary number\n",
    "    binary = '{0:02b}'.format(index)\n",
    "    # get qubit at digit in binary state (positions of qubits : q0, q1, q2, q3) (figuratively, not actually, we are in superposition after all)\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    # this_phase_gate = MCPhaseGate(value, 3, label=\"this_phase_gate\")\n",
    "    # qc.this_phase_gate(0, 1, 2, 3)\n",
    "    # perform controlled phase shift (for more qubits probably possible using ControlledGate() and MatrixGate()\n",
    "    insert_list.append(cphase(control_params[index])(*regular_qubits))\n",
    "    # \"undo\" the NOT-gates to get back to previous states = apply another not\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    qc.append(insert_list, strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# loop over weights\n",
    "for w in range(size):\n",
    "    insert_list = []\n",
    "    # index as binary number\n",
    "    binary = '{0:02b}'.format(w)\n",
    "    # get qubit at digit in binary state (positions of qubits : q0, q1, q2, q3) (figuratively, not actually, we are in superposition after all)\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    # this_phase_gate = MCPhaseGate(value, 3, label=\"this_phase_gate\")\n",
    "    # qc.this_phase_gate(0, 1, 2, 3)\n",
    "    # perform conjugate transpose controlled phase shift\n",
    "    insert_list.append(cphase((-1) * control_params1[w])(*regular_qubits))\n",
    "    # \"undo\" the NOT-gates to get back to previous states = apply another not\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    qc.append(insert_list, strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# apply Hadamard gate to all regular qubits\n",
    "qc.append(H.on_each(*regular_qubits), strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# apply X gate to all regular qubits\n",
    "qc.append(X.on_each(*regular_qubits), strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# collect combined state from all regular qubits with ancilla qubit using Toffoli-Gate\n",
    "# Toffoli-Gate does not work in TFQ -> implement decomposition (compare https://en.wikipedia.org/wiki/Toffoli_gate#/media/File:Qcircuit_ToffolifromCNOT.svg)\n",
    "qc.append([H(ancilla), CNOT(regular_qubits[1], ancilla), cirq.inverse(T(ancilla)), CNOT(regular_qubits[0], ancilla), T(ancilla), CNOT(regular_qubits[1], ancilla), cirq.inverse(T(ancilla)), CNOT(regular_qubits[0], ancilla), T(ancilla), T(regular_qubits[1]), H(ancilla), CNOT(regular_qubits[0], regular_qubits[1]), cirq.inverse(T(regular_qubits[1])), T(regular_qubits[0]), CNOT(regular_qubits[0], regular_qubits[1])], strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# draw circuit\n",
    "SVGCircuit(qc)\n",
    "# end circuit\n",
    "\n",
    "# values to initialize the weights (?)\n",
    "np.random.seed(seed=69)\n",
    "int_values = np.random.rand((len(control_params1)))*np.pi\n",
    "\n",
    "measurement = [Z(ancilla)]\n",
    "\n",
    "# This is needed because of Note here:\n",
    "# https://www.tensorflow.org/quantum/api_docs/python/tfq/layers/Expectation\n",
    "unused = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(4, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "expectation = SplitBackpropQ(control_params, control_params1, int_values, measurement)([unused, x])\n",
    "#expectation = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=[unused, all_inputs], outputs=expectation)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\"\"\"\n",
    "Let's visualize our connectivity graph:\n",
    "\"\"\"\n",
    "\n",
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "model.summary()\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "x_train = []\n",
    "y_train = []\n",
    "for x, y in train_ds:\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "for x, y in val_ds:\n",
    "    x_val.append(x)\n",
    "    y_val.append(y)\n",
    "x_val = tf.convert_to_tensor(x_val)\n",
    "y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "#n = train_ds.cardinality().numpy()\n",
    "#n_val = val_ds.cardinality().numpy()\n",
    "\n",
    "n = x_train.shape[0]\n",
    "n_val = x_val.shape[0]\n",
    "\n",
    "model.fit(x=[tfq.convert_to_tensor([qc for _ in range(n)]), x_train], y=y_train, epochs=50, batch_size=32, validation_data=([tfq.convert_to_tensor([qc for _ in range(n_val)]), x_val], y_val), validation_batch_size=32)\n",
    "\n",
    "\"\"\"\n",
    "We quickly get to 80% validation accuracy.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Inference on new data\n",
    "To get a prediction for a new sample, you can simply call `model.predict()`. There are\n",
    "just two things you need to do:\n",
    "1. wrap scalars into a list so as to have a batch dimension (models only process batches\n",
    "of data, not single samples)\n",
    "2. Call `convert_to_tensor` on each feature\n",
    "\"\"\"\n",
    "\n",
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
