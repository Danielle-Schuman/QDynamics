{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1Mj-RBCn8MZ"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al80f-lPoJjh"
   },
   "source": [
    "## Getting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "r3iHOMsdnNiq",
    "outputId": "48316653-e273-470c-daa6-f04891dde84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klone nach 'PINNs' ...\n",
      "remote: Enumerating objects: 741, done.\u001b[K\n",
      "remote: Total 741 (delta 0), reused 0 (delta 0), pack-reused 741\u001b[K\n",
      "Empfange Objekte: 100% (741/741), 474.47 MiB | 10.68 MiB/s, Fertig.\n",
      "LÃ¶se Unterschiede auf: 100% (66/66), Fertig.\n",
      "Aktualisiere Dateien: 100% (561/561), Fertig.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/maziarraissi/PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gtoc_dXgoOZq"
   },
   "source": [
    "## Setting up modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNMtDjXkFHaN"
   },
   "source": [
    "TeX packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TaZCKcDsEVRP",
    "outputId": "be5e2e31-f422-4c58-a821-0d7f7a38af9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -qq install texlive-fonts-recommended texlive-fonts-extra dvipng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Otc4Ap7qFMlf"
   },
   "source": [
    "Pip modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "collapsed": true,
    "id": "srpq4aQNoQ1E",
    "outputId": "78582ecd-9664-4784-ab57-ef8276779e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyDOE\n",
      "  Using cached pyDOE-0.3.8-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.4.1)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.3.1-cp37-cp37m-macosx_10_9_x86_64.whl (165.1 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.19.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.19.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Installing collected packages: tensorflow, pyDOE\n",
      "Successfully installed pyDOE-0.3.8 tensorflow-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pyDOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksKujMvUFRNW"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZEDn2fqlqctT",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# Manually making sure the numpy random seeds are \"the same\" on all devices\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODGREPvZpqUz"
   },
   "source": [
    "## Utilities: Data preparation, logger class and plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FgPvqJiYFnYG",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyDOE import lhs\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
    "repoPath = os.path.join(\".\", \"PINNs\")\n",
    "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
    "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
    "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
    "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")\n",
    "\n",
    "sys.path.insert(0, utilsPath)\n",
    "from plotting import newfig, savefig\n",
    "\n",
    "# prepare data\n",
    "def prep_data(path, N_u=None, N_f=None, N_n=None, q=None, ub=None, lb=None, noise=0.0, idx_t_0=None, idx_t_1=None, N_0=None, N_1=None):\n",
    "    # Reading external data [t is 100x1, usol is 256x100 (solution), x is 256x1]\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    # Flatten makes [[]] into [], [:,None] makes it a column vector\n",
    "    t = data['t'].flatten()[:,None] # T x 1\n",
    "    x = data['x'].flatten()[:,None] # N x 1\n",
    "\n",
    "    # Keeping the 2D data for the solution data (real() is maybe to make it float by default, in case of zeroes)\n",
    "    Exact_u = np.real(data['usol']).T # T x N\n",
    "\n",
    "    if N_n != None and q != None and ub != None and lb != None and idx_t_0 != None and idx_t_1 != None:\n",
    "      dt = t[idx_t_1] - t[idx_t_0]\n",
    "      idx_x = np.random.choice(Exact_u.shape[1], N_n, replace=False) \n",
    "      x_0 = x[idx_x,:]\n",
    "      u_0 = Exact_u[idx_t_0:idx_t_0+1,idx_x].T\n",
    "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
    "        \n",
    "      # Boudanry data\n",
    "      x_1 = np.vstack((lb, ub))\n",
    "      \n",
    "      # Test data\n",
    "      x_star = x\n",
    "      u_star = Exact_u[idx_t_1,:]\n",
    "\n",
    "      # Load IRK weights\n",
    "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
    "      IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
    "      IRK_times = tmp[q**2+q:]\n",
    "\n",
    "      return x, t, dt, Exact_u, x_0, u_0, x_1, x_star, u_star, IRK_weights, IRK_times\n",
    "\n",
    "    # Meshing x and t in 2D (256,100)\n",
    "    X, T = np.meshgrid(x,t)\n",
    "\n",
    "    # Preparing the inputs x and t (meshed as X, T) for predictions in one single array, as X_star\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "    # Preparing the testing u_star\n",
    "    u_star = Exact_u.flatten()[:,None]\n",
    "                \n",
    "    # Noiseless data TODO: add support for noisy data    \n",
    "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
    "    X_u_train = X_star[idx,:]\n",
    "    u_train = u_star[idx,:]\n",
    "\n",
    "    if N_0 != None and N_1 != None:\n",
    "      Exact_u = Exact_u.T\n",
    "      idx_x = np.random.choice(Exact_u.shape[0], N_0, replace=False)\n",
    "      x_0 = x[idx_x,:]\n",
    "      u_0 = Exact_u[idx_x,idx_t_0][:,None]\n",
    "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
    "          \n",
    "      idx_x = np.random.choice(Exact_u.shape[0], N_1, replace=False)\n",
    "      x_1 = x[idx_x,:]\n",
    "      u_1 = Exact_u[idx_x,idx_t_1][:,None]\n",
    "      u_1 = u_1 + noise*np.std(u_1)*np.random.randn(u_1.shape[0], u_1.shape[1])\n",
    "      \n",
    "      dt = np.asscalar(t[idx_t_1] - t[idx_t_0])        \n",
    "      q = int(np.ceil(0.5*np.log(np.finfo(float).eps)/np.log(dt)))\n",
    "\n",
    "      # Load IRK weights\n",
    "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
    "      weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
    "      IRK_alpha = weights[0:-1,:]\n",
    "      IRK_beta = weights[-1:,:] \n",
    "      return x_0, u_0, x_1, u_1, x, t, dt, q, Exact_u, IRK_alpha, IRK_beta\n",
    "\n",
    "    if N_f == None:\n",
    "      lb = X_star.min(axis=0)\n",
    "      ub = X_star.max(axis=0) \n",
    "      return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, ub, lb\n",
    "\n",
    "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
    "    lb = X_star.min(axis=0)\n",
    "    ub = X_star.max(axis=0) \n",
    "    #Â Getting the initial conditions (t=0)\n",
    "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "    uu1 = Exact_u[0:1,:].T\n",
    "    # Getting the lowest boundary conditions (x=-1) \n",
    "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "    uu2 = Exact_u[:,0:1]\n",
    "    # Getting the highest boundary conditions (x=1) \n",
    "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "    uu3 = Exact_u[:,-1:]\n",
    "    # Stacking them in multidimensional tensors for training (X_u_train is for now the continuous boundaries)\n",
    "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "    u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "    #â¯Generating the x and t collocation points for f, with each having a N_f size\n",
    "    # We pointwise add and multiply to spread the LHS over the 2D domain\n",
    "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "\n",
    "    # Generating a uniform random sample from ints between 0, and the size of x_u_train, of size N_u (initial data size) and without replacement (unique)\n",
    "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "    # Getting the corresponding X_u_train (which is now scarce boundary/initial coordinates)\n",
    "    X_u_train = X_u_train[idx,:]\n",
    "    #â¯Getting the corresponding u_train\n",
    "    u_train = u_train [idx,:]\n",
    "\n",
    "    return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, X_f_train, ub, lb\n",
    "\n",
    "# define logger class\n",
    "class Logger(object):\n",
    "  def __init__(self, frequency=10):\n",
    "    print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "    print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "    print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
    "\n",
    "    self.start_time = time.time()\n",
    "    self.frequency = frequency\n",
    "\n",
    "  def __get_elapsed(self):\n",
    "    return datetime.fromtimestamp(time.time() - self.start_time).strftime(\"%M:%S\")\n",
    "\n",
    "  def __get_error_u(self):\n",
    "    return self.error_fn()\n",
    "\n",
    "  def set_error_fn(self, error_fn):\n",
    "    self.error_fn = error_fn\n",
    "  \n",
    "  def log_train_start(self, model):\n",
    "    print(\"\\nTraining started\")\n",
    "    print(\"================\")\n",
    "    self.model = model\n",
    "    print(self.model.summary())\n",
    "\n",
    "  def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
    "    if epoch % self.frequency == 0:\n",
    "      print(f\"{'nt_epoch' if is_iter else 'tf_epoch'} = {epoch:6d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  error = {self.__get_error_u():.4e}  \" + custom)\n",
    "\n",
    "  def log_train_opt(self, name):\n",
    "    # print(f\"tf_epoch =      0  elapsed = 00:00  loss = 2.7391e-01  error = 9.0843e-01\")\n",
    "    print(f\"ââ Starting {name} optimization ââ\")\n",
    "\n",
    "  def log_train_end(self, epoch, custom=\"\"):\n",
    "    print(\"==================\")\n",
    "    print(f\"Training finished (epoch {epoch}): duration = {self.__get_elapsed()}  error = {self.__get_error_u():.4e}  \" + custom)\n",
    "\n",
    "# for plotting\n",
    "def plot_inf_cont_results(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, file=None):\n",
    "\n",
    "  # Interpolating the results on the whole (x,t) domain.\n",
    "  # griddata(points, values, points at which to interpolate, method)\n",
    "  U_pred = griddata(X_star, u_pred, (X, T), method='cubic')\n",
    "\n",
    "  # Creating the figures\n",
    "  fig, ax = newfig(1.0, 1.1)\n",
    "  ax.axis('off')\n",
    "\n",
    "  ####### Row 0: u(t,x) ##################    \n",
    "  gs0 = gridspec.GridSpec(1, 2)\n",
    "  gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "  ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "  h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "  divider = make_axes_locatable(ax)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "  fig.colorbar(h, cax=cax)\n",
    "\n",
    "  ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
    "\n",
    "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "  ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "  ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "  ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
    "\n",
    "  ax.set_xlabel('$t$')\n",
    "  ax.set_ylabel('$x$')\n",
    "  ax.legend(frameon=False, loc = 'best')\n",
    "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
    "\n",
    "  ####### Row 1: u(t,x) slices ##################    \n",
    "  gs1 = gridspec.GridSpec(1, 3)\n",
    "  gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "  ax = plt.subplot(gs1[0, 0])\n",
    "  ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "  ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "  ax.set_xlabel('$x$')\n",
    "  ax.set_ylabel('$u(t,x)$')    \n",
    "  ax.set_title('$t = 0.25$', fontsize = 10)\n",
    "  ax.axis('square')\n",
    "  ax.set_xlim([-1.1,1.1])\n",
    "  ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "  ax = plt.subplot(gs1[0, 1])\n",
    "  ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "  ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "  ax.set_xlabel('$x$')\n",
    "  ax.set_ylabel('$u(t,x)$')\n",
    "  ax.axis('square')\n",
    "  ax.set_xlim([-1.1,1.1])\n",
    "  ax.set_ylim([-1.1,1.1])\n",
    "  ax.set_title('$t = 0.50$', fontsize = 10)\n",
    "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "  ax = plt.subplot(gs1[0, 2])\n",
    "  ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "  ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "  ax.set_xlabel('$x$')\n",
    "  ax.set_ylabel('$u(t,x)$')\n",
    "  ax.axis('square')\n",
    "  ax.set_xlim([-1.1,1.1])\n",
    "  ax.set_ylim([-1.1,1.1])    \n",
    "  ax.set_title('$t = 0.75$', fontsize = 10)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  if file != None:\n",
    "    fig.savefig(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Azv7DZp0M-"
   },
   "source": [
    "## Define custom lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OjvMe1Avpvh9",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/yaroslavvb/stuff/blob/master/eager_lbfgs/eager_lbfgs.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Time tracking functions\n",
    "global_time_list = []\n",
    "global_last_time = 0\n",
    "def reset_time():\n",
    "  global global_time_list, global_last_time\n",
    "  global_time_list = []\n",
    "  global_last_time = time.perf_counter()\n",
    "  \n",
    "def record_time():\n",
    "  global global_last_time, global_time_list\n",
    "  new_time = time.perf_counter()\n",
    "  global_time_list.append(new_time - global_last_time)\n",
    "  global_last_time = time.perf_counter()\n",
    "  #print(\"step: %.2f\"%(global_time_list[-1]*1000))\n",
    "\n",
    "def last_time():\n",
    "  \"\"\"Returns last interval records in millis.\"\"\"\n",
    "  global global_last_time, global_time_list\n",
    "  if global_time_list:\n",
    "    return 1000 * global_time_list[-1]\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def dot(a, b):\n",
    "  \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
    "  return tf.reduce_sum(a*b)\n",
    "\n",
    "def verbose_func(s):\n",
    "  print(s)\n",
    "\n",
    "final_loss = None\n",
    "times = []\n",
    "def lbfgs(opfunc, x, config, state, do_verbose, log_fn):\n",
    "  \"\"\"port of lbfgs.lua, using TensorFlow eager mode.\n",
    "  \"\"\"\n",
    "\n",
    "  if config.maxIter == 0:\n",
    "    return\n",
    "\n",
    "  global final_loss, times\n",
    "  \n",
    "  maxIter = config.maxIter\n",
    "  maxEval = config.maxEval or maxIter*1.25\n",
    "  tolFun = config.tolFun or 1e-5\n",
    "  tolX = config.tolX or 1e-19\n",
    "  nCorrection = config.nCorrection or 100\n",
    "  lineSearch = config.lineSearch\n",
    "  lineSearchOpts = config.lineSearchOptions\n",
    "  learningRate = config.learningRate or 1\n",
    "  isverbose = config.verbose or False\n",
    "\n",
    "  # verbose function\n",
    "  if isverbose:\n",
    "    verbose = verbose_func\n",
    "  else:\n",
    "    verbose = lambda x: None\n",
    "\n",
    "    # evaluate initial f(x) and df/dx\n",
    "  f, g = opfunc(x)\n",
    "\n",
    "  f_hist = [f]\n",
    "  currentFuncEval = 1\n",
    "  state.funcEval = state.funcEval + 1\n",
    "  p = g.shape[0]\n",
    "\n",
    "  # check optimality of initial point\n",
    "  tmp1 = tf.abs(g)\n",
    "  if tf.reduce_sum(tmp1) <= tolFun:\n",
    "    verbose(\"optimality condition below tolFun\")\n",
    "    return x, f_hist\n",
    "\n",
    "  # optimize for a max of maxIter iterations\n",
    "  nIter = 0\n",
    "  times = []\n",
    "  while nIter < maxIter:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # keep track of nb of iterations\n",
    "    nIter = nIter + 1\n",
    "    state.nIter = state.nIter + 1\n",
    "\n",
    "    ############################################################\n",
    "    ## compute gradient descent direction\n",
    "    ############################################################\n",
    "    if state.nIter == 1:\n",
    "      d = -g\n",
    "      old_dirs = []\n",
    "      old_stps = []\n",
    "      Hdiag = 1\n",
    "    else:\n",
    "      # do lbfgs update (update memory)\n",
    "      y = g - g_old\n",
    "      s = d*t\n",
    "      ys = dot(y, s)\n",
    "      \n",
    "      if ys > 1e-10:\n",
    "        # updating memory\n",
    "        if len(old_dirs) == nCorrection:\n",
    "          # shift history by one (limited-memory)\n",
    "          del old_dirs[0]\n",
    "          del old_stps[0]\n",
    "\n",
    "        # store new direction/step\n",
    "        old_dirs.append(s)\n",
    "        old_stps.append(y)\n",
    "\n",
    "        # update scale of initial Hessian approximation\n",
    "        Hdiag = ys/dot(y, y)\n",
    "\n",
    "      # compute the approximate (L-BFGS) inverse Hessian \n",
    "      # multiplied by the gradient\n",
    "      k = len(old_dirs)\n",
    "\n",
    "      # need to be accessed element-by-element, so don't re-type tensor:\n",
    "      ro = [0]*nCorrection\n",
    "      for i in range(k):\n",
    "        ro[i] = 1/dot(old_stps[i], old_dirs[i])\n",
    "        \n",
    "\n",
    "      # iteration in L-BFGS loop collapsed to use just one buffer\n",
    "      # need to be accessed element-by-element, so don't re-type tensor:\n",
    "      al = [0]*nCorrection\n",
    "\n",
    "      q = -g\n",
    "      for i in range(k-1, -1, -1):\n",
    "        al[i] = dot(old_dirs[i], q) * ro[i]\n",
    "        q = q - al[i]*old_stps[i]\n",
    "\n",
    "      # multiply by initial Hessian\n",
    "      r = q*Hdiag\n",
    "      for i in range(k):\n",
    "        be_i = dot(old_stps[i], r) * ro[i]\n",
    "        r += (al[i]-be_i)*old_dirs[i]\n",
    "        \n",
    "      d = r\n",
    "      # final direction is in r/d (same object)\n",
    "\n",
    "    g_old = g\n",
    "    f_old = f\n",
    "    \n",
    "    ############################################################\n",
    "    ## compute step length\n",
    "    ############################################################\n",
    "    # directional derivative\n",
    "    gtd = dot(g, d)\n",
    "\n",
    "    # check that progress can be made along that direction\n",
    "    if gtd > -tolX:\n",
    "      verbose(\"Can not make progress along direction.\")\n",
    "      break\n",
    "\n",
    "    # reset initial guess for step size\n",
    "    if state.nIter == 1:\n",
    "      tmp1 = tf.abs(g)\n",
    "      t = min(1, 1/tf.reduce_sum(tmp1))\n",
    "    else:\n",
    "      t = learningRate\n",
    "\n",
    "\n",
    "    # optional line search: user function\n",
    "    lsFuncEval = 0\n",
    "    if lineSearch and isinstance(lineSearch) == types.FunctionType:\n",
    "      # perform line search, using user function\n",
    "      f,g,x,t,lsFuncEval = lineSearch(opfunc,x,t,d,f,g,gtd,lineSearchOpts)\n",
    "      f_hist.append(f)\n",
    "    else:\n",
    "      # no line search, simply move with fixed-step\n",
    "      x += t*d\n",
    "      \n",
    "      if nIter != maxIter:\n",
    "        # re-evaluate function only if not in last iteration\n",
    "        # the reason we do this: in a stochastic setting,\n",
    "        # no use to re-evaluate that function here\n",
    "        f, g = opfunc(x)\n",
    "        lsFuncEval = 1\n",
    "        f_hist.append(f)\n",
    "\n",
    "\n",
    "    # update func eval\n",
    "    currentFuncEval = currentFuncEval + lsFuncEval\n",
    "    state.funcEval = state.funcEval + lsFuncEval\n",
    "\n",
    "    ############################################################\n",
    "    ## check conditions\n",
    "    ############################################################\n",
    "    if nIter == maxIter:\n",
    "      break\n",
    "\n",
    "    if currentFuncEval >= maxEval:\n",
    "      # max nb of function evals\n",
    "      verbose('max nb of function evals')\n",
    "      break\n",
    "\n",
    "    tmp1 = tf.abs(g)\n",
    "    if tf.reduce_sum(tmp1) <=tolFun:\n",
    "      # check optimality\n",
    "      verbose('optimality condition below tolFun')\n",
    "      break\n",
    "    \n",
    "    tmp1 = tf.abs(d*t)\n",
    "    if tf.reduce_sum(tmp1) <= tolX:\n",
    "      # step size below tolX\n",
    "      verbose('step size below tolX')\n",
    "      break\n",
    "\n",
    "    if tf.abs(f-f_old) < tolX:\n",
    "      # function value changing less than tolX\n",
    "      verbose('function value changing less than tolX'+str(tf.abs(f-f_old)))\n",
    "      break\n",
    "\n",
    "    if do_verbose:\n",
    "      log_fn(nIter, f.numpy(), True)\n",
    "      #print(\"Step %3d loss %6.5f msec %6.3f\"%(nIter, f.numpy(), last_time()))\n",
    "      record_time()\n",
    "      times.append(last_time())\n",
    "\n",
    "    if nIter == maxIter - 1:\n",
    "      final_loss = f.numpy()\n",
    "\n",
    "\n",
    "  # save state\n",
    "  state.old_dirs = old_dirs\n",
    "  state.old_stps = old_stps\n",
    "  state.Hdiag = Hdiag\n",
    "  state.g_old = g_old\n",
    "  state.f_old = f_old\n",
    "  state.t = t\n",
    "  state.d = d\n",
    "\n",
    "  return x, f_hist, currentFuncEval\n",
    "\n",
    "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
    "class dummy(object):\n",
    "  pass\n",
    "\n",
    "class Struct(dummy):\n",
    "  def __getattribute__(self, key):\n",
    "    if key == '__dict__':\n",
    "      return super(dummy, self).__getattribute__('__dict__')\n",
    "    return self.__dict__.get(key, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOT-E8C4oAJN"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Qrt3ECzcLHp"
   },
   "source": [
    "Burger' Equation:\n",
    "$$u_t + u u_x - \\nu u_{xx} = 0$$\n",
    "\n",
    "With $x \\in [-1,1],\\quad t \\in [0,1],\\quad \\nu = (0.01/\\pi)$.\n",
    "\n",
    "And $u(0,x) = -\\sin(\\pi x),\\quad u(t,-1) = u(t,1) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8CHqrpafela"
   },
   "source": [
    "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
    "$$f := u_t + u u_x - \\nu u_{xx}.$$\n",
    "\n",
    "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
    "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_f}|f(t_f^i,x_f^i)|^2,$$\n",
    "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ and $\\{t_f^i, x_f^i\\}_{i=1}^{N_f}$ respectively the initial/boundary data on $u(t,x)$ and collocations points for $f(t,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9Ko6L87J2v_"
   },
   "source": [
    "### Hyperparameters for the classical PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jwWhiecUqbAo",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Data size on the solution u\n",
    "N_u = 50\n",
    "# Collocation points size, where weâll check for f = 0\n",
    "N_f = 10000\n",
    "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
    "\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "#layers = [2, 20, 2, 3, 2, 20, 1]\n",
    "\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "tf_epochs = 100\n",
    "tf_optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate=0.1,\n",
    "  beta_1=0.99,\n",
    "  epsilon=1e-1)\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "nt_epochs = 500 #1000-2000 way more accurate but this is quicker ...\n",
    "nt_config = Struct()\n",
    "nt_config.learningRate = 0.8\n",
    "nt_config.maxIter = nt_epochs\n",
    "nt_config.nCorrection = 50\n",
    "nt_config.tolFun = 1.0 * np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkimJNtepkKi"
   },
   "source": [
    "## PINNÂ class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KVm9UCvvlyY_"
   },
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(object):\n",
    "  def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu):\n",
    "    # Descriptive Sequential Keras model [2, 20, â¦, 20, 1]\n",
    "    self.u_model = tf.keras.Sequential()\n",
    "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
    "    self.u_model.add(tf.keras.layers.Lambda(\n",
    "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
    "    for width in layers[1:]: # add dense layers\n",
    "      self.u_model.add(tf.keras.layers.Dense(\n",
    "              width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal'))\n",
    "\n",
    "    # Computing the sizes of weights/biases for future decomposition\n",
    "    self.sizes_w = []\n",
    "    self.sizes_b = []\n",
    "    for i, width in enumerate(layers):\n",
    "      if i != 1:\n",
    "        self.sizes_w.append(int(width * layers[1]))\n",
    "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
    "\n",
    "    self.nu = nu\n",
    "    self.optimizer = optimizer\n",
    "    self.logger = logger\n",
    "\n",
    "    self.dtype = tf.float32\n",
    "\n",
    "    #Â Separating the collocation coordinates\n",
    "    self.x_f = tf.convert_to_tensor(X_f[:, 0:1], dtype=self.dtype)\n",
    "    self.t_f = tf.convert_to_tensor(X_f[:, 1:2], dtype=self.dtype)\n",
    "    \n",
    "  # Defining custom loss\n",
    "  def __loss(self, u, u_pred):\n",
    "    f_pred = self.f_model()\n",
    "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
    "      tf.reduce_mean(tf.square(f_pred))\n",
    "\n",
    "  def __grad(self, X, u):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss_value = self.__loss(u, self.u_model(X))\n",
    "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
    "\n",
    "  def __wrap_training_variables(self):\n",
    "    var = self.u_model.trainable_variables\n",
    "    return var\n",
    "\n",
    "  # The actual PINN\n",
    "  def f_model(self):\n",
    "    # Using the new GradientTape paradigm of TF2.0,\n",
    "    # which keeps track of operations to get the gradient at runtime\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "      # Watching the two inputs weâll need later, x and t\n",
    "      tape.watch(self.x_f)\n",
    "      tape.watch(self.t_f)\n",
    "      # Packing together the inputs\n",
    "      X_f = tf.stack([self.x_f[:,0], self.t_f[:,0]], axis=1)\n",
    "\n",
    "      # Getting the prediction\n",
    "      u = self.u_model(X_f)\n",
    "      # Deriving INSIDE the tape (since weâll need the x derivative of this later, u_xx)\n",
    "      u_x = tape.gradient(u, self.x_f)\n",
    "    \n",
    "    # Getting the other derivatives\n",
    "    u_xx = tape.gradient(u_x, self.x_f)\n",
    "    u_t = tape.gradient(u, self.t_f)\n",
    "\n",
    "    # Letting the tape go\n",
    "    del tape\n",
    "\n",
    "    nu = self.get_params(numpy=True)\n",
    "\n",
    "    # Buidling the PINNs\n",
    "    return u_t + u*u_x - nu*u_xx\n",
    "\n",
    "  def get_params(self, numpy=False):\n",
    "    return self.nu\n",
    "\n",
    "  def get_weights(self):\n",
    "    w = []\n",
    "    for layer in self.u_model.layers[1:]:\n",
    "      weights_biases = layer.get_weights()\n",
    "      weights = weights_biases[0].flatten()\n",
    "      biases = weights_biases[1]\n",
    "      w.extend(weights)\n",
    "      w.extend(biases)\n",
    "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
    "\n",
    "  def set_weights(self, w):\n",
    "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
    "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
    "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
    "      weights = w[start_weights:end_weights]\n",
    "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
    "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
    "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
    "      weights_biases = [weights, biases]\n",
    "      layer.set_weights(weights_biases)\n",
    "\n",
    "  def summary(self):\n",
    "    return self.u_model.summary()\n",
    "\n",
    "  # The training function\n",
    "  def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
    "    self.logger.log_train_start(self)\n",
    "\n",
    "    # Creating the tensors\n",
    "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
    "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
    "\n",
    "    self.logger.log_train_opt(\"Adam\")\n",
    "    for epoch in range(tf_epochs):\n",
    "      # Optimization step\n",
    "      loss_value, grads = self.__grad(X_u, u)\n",
    "      self.optimizer.apply_gradients(zip(grads, self.__wrap_training_variables()))\n",
    "      self.logger.log_train_epoch(epoch, loss_value)\n",
    "    \n",
    "    self.logger.log_train_opt(\"LBFGS\")\n",
    "    def loss_and_flat_grad(w):\n",
    "      with tf.GradientTape() as tape:\n",
    "        self.set_weights(w)\n",
    "        loss_value = self.__loss(u, self.u_model(X_u))\n",
    "      grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
    "      grad_flat = []\n",
    "      for g in grad:\n",
    "        grad_flat.append(tf.reshape(g, [-1]))\n",
    "      grad_flat =  tf.concat(grad_flat, 0)\n",
    "      return loss_value, grad_flat\n",
    "    # tfp.optimizer.lbfgs_minimize(\n",
    "    #   loss_and_flat_grad,\n",
    "    #   initial_position=self.get_weights(),\n",
    "    #   num_correction_pairs=nt_config.nCorrection,\n",
    "    #   max_iterations=nt_config.maxIter,\n",
    "    #   f_relative_tolerance=nt_config.tolFun,\n",
    "    #   tolerance=nt_config.tolFun,\n",
    "    #   parallel_iterations=6)\n",
    "    \"\"\"lbfgs(loss_and_flat_grad,\n",
    "      self.get_weights(),\n",
    "      nt_config, Struct(), True,\n",
    "      lambda epoch, loss, is_iter:\n",
    "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\"\"\"\n",
    "\n",
    "    self.logger.log_train_end(tf_epochs + nt_config.maxIter)\n",
    "\n",
    "  def predict(self, X_star):\n",
    "    u_star = self.u_model(X_star)\n",
    "    f_star = self.f_model()\n",
    "    return u_star, f_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FzMd65dpoHo"
   },
   "source": [
    "## Training and plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SEKkpHvApf46",
    "lines_to_next_cell": 2,
    "outputId": "8a6c27ef-8be5-431b-ab60-c4ddd6edb429",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: False\n",
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "lambda_layer (Lambda)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,021\n",
      "Trainable params: 3,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "ââ Starting Adam optimization ââ\n",
      "tf_epoch =      0  elapsed = 00:00  loss = 5.5133e-01  error = 9.5844e-01  \n",
      "tf_epoch =     10  elapsed = 00:03  loss = 2.6452e-01  error = 9.3412e-01  \n",
      "tf_epoch =     20  elapsed = 00:06  loss = 2.2908e-01  error = 7.8812e-01  \n",
      "tf_epoch =     30  elapsed = 00:08  loss = 2.0818e-01  error = 8.1507e-01  \n",
      "tf_epoch =     40  elapsed = 00:11  loss = 2.0806e-01  error = 8.1258e-01  \n",
      "tf_epoch =     50  elapsed = 00:13  loss = 1.9113e-01  error = 6.1637e-01  \n",
      "tf_epoch =     60  elapsed = 00:15  loss = 1.7994e-01  error = 7.1227e-01  \n",
      "tf_epoch =     70  elapsed = 00:17  loss = 1.7349e-01  error = 6.3453e-01  \n",
      "tf_epoch =     80  elapsed = 00:19  loss = 1.7529e-01  error = 6.4012e-01  \n",
      "tf_epoch =     90  elapsed = 00:22  loss = 1.7963e-01  error = 7.4018e-01  \n",
      "ââ Starting LBFGS optimization ââ\n",
      "==================\n",
      "Training finished (epoch 600): duration = 00:24  error = 6.4783e-01  \n"
     ]
    }
   ],
   "source": [
    "# Getting the data\n",
    "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
    "x, t, X, T, Exact_u, X_star, u_star, \\\n",
    "  X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
    "\n",
    "# Creating the model and training\n",
    "logger = Logger(frequency=10)\n",
    "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, X_f, ub, lb, nu=0.01/np.pi)\n",
    "def error():\n",
    "  u_pred, _ = pinn.predict(X_star)\n",
    "  return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "logger.set_error_fn(error)\n",
    "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
    "\n",
    "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
    "u_pred, f_pred = pinn.predict(X_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "Wf1QXaK5PlUh",
    "lines_to_next_cell": 0,
    "outputId": "7c9c2826-ba07-433a-ab68-73cd0f7ea2e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 388.543x264.146 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_inf_cont_results(X_star, u_pred.numpy().flatten(), X_u_train, u_train,\n",
    "  Exact_u, X, T, x, t, file = \"plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-3.1513e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maxls pennylane try, does not work unfortunately\n",
    "import pennylane as qml\n",
    "\n",
    "\n",
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit.tf\", wires=n_qubits) # \"lightning.qubit\" fast, C++ device\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))\n",
    "\n",
    "weight_shapes = {\"weights\": (3, n_qubits, 3)}\n",
    "\n",
    "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# TFQ / Cirq code for quantum layer: 1 node, input-vector-length = 4 (TODO: make 16)\n",
    "import tensorflow_quantum as tfq\n",
    "import cirq\n",
    "from cirq import H, X, cphase, CNOT, Z, T\n",
    "from cirq.circuits import InsertStrategy\n",
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "\n",
    "# adapted from https://github.com/ghellstern/QuantumNN/blob/master/Multi-QBit-Classifier%20TF%20NN-Encoding_Github.ipynb\n",
    "class SplitBackpropQ(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, upstream_symbols, managed_symbols, managed_init_vals,\n",
    "                 operators):\n",
    "        \"\"\"Create a layer that splits backprop between several variables.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            upstream_symbols: Python iterable of symbols to bakcprop\n",
    "                through this layer.\n",
    "            managed_symbols: Python iterable of symbols to backprop\n",
    "                into variables managed by this layer.\n",
    "            managed_init_vals: Python iterable of initial values\n",
    "                for managed_symbols.\n",
    "            operators: Python iterable of operators to use for expectation.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(SplitBackpropQ)\n",
    "        self.all_symbols = upstream_symbols + managed_symbols\n",
    "        self.upstream_symbols = upstream_symbols\n",
    "        self.managed_symbols = managed_symbols\n",
    "        self.managed_init = managed_init_vals\n",
    "        self.ops = operators\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.managed_weights = self.add_weight(\n",
    "            shape=(1, len(self.managed_symbols)),\n",
    "            initializer=tf.constant_initializer(self.managed_init))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs are: circuit tensor, upstream values\n",
    "        upstream_shape = tf.gather(tf.shape(inputs[0]), 0)\n",
    "        tiled_up_weights = tf.tile(self.managed_weights, [upstream_shape, 1])\n",
    "        joined_params = tf.concat([inputs[1], tiled_up_weights], 1)\n",
    "        return tfq.layers.Expectation()(inputs[0],\n",
    "                                        operators=measurement,\n",
    "                                        symbol_names=self.all_symbols,\n",
    "                                        symbol_values=joined_params)\n",
    "\n",
    "\n",
    "# TODO: Normalize weights and inputs to be between [0, pi / 2]\n",
    "# TODO: replace CPhase-Gate with Multi-controlled Phase gate and use 4 qubits, Input-Size 16 instead\n",
    "# 2 regular qubits, 1 ancilla\n",
    "number_qubits = 3\n",
    "number_regular_qubits = number_qubits - 1\n",
    "\n",
    "# specify parameters to set later with NN inputs and weights using Keras + TFQ\n",
    "regular_qubits = [cirq.GridQubit(i, 0) for i in range(number_regular_qubits)]\n",
    "ancilla = cirq.GridQubit(number_regular_qubits, 0)\n",
    "control_params = sympy.symbols('i0, i1, i2, i3')\n",
    "control_params1 = sympy.symbols('w0, w1, w2, w3')\n",
    "\n",
    "# specify cirq circuit\n",
    "qc = cirq.Circuit()\n",
    "size = len(regular_qubits) ** 2\n",
    "# subtract first input from other inputs to save gates\n",
    "#inputs = []\n",
    "#for i in range(1, size):\n",
    "    #inputs.append(control_params[i] - control_params[0])\n",
    "# do the same for weights\n",
    "#weights = []\n",
    "#for i in range(1, size):\n",
    "    #weights.append(control_params1[i] - control_params1[0])\n",
    "# apply Hadamard gate to all regular qubits to create a superposition\n",
    "qc.append(H.on_each(*regular_qubits))\n",
    "# loop over all inputs in inputvector to encode them to the right base states using phase-shifts\n",
    "for index in range(size):\n",
    "    insert_list = []\n",
    "    # index as binary number\n",
    "    binary = '{0:02b}'.format(index)\n",
    "    # get qubit at digit in binary state (positions of qubits : q0, q1, q2, q3) (figuratively, not actually, we are in superposition after all)\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    # this_phase_gate = MCPhaseGate(value, 3, label=\"this_phase_gate\")\n",
    "    # qc.this_phase_gate(0, 1, 2, 3)\n",
    "    # perform controlled phase shift (for more qubits probably possible using ControlledGate() and MatrixGate()\n",
    "    insert_list.append(cphase(control_params[index])(*regular_qubits))\n",
    "    # \"undo\" the NOT-gates to get back to previous states = apply another not\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    qc.append(insert_list, strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# loop over weights\n",
    "for w in range(size):\n",
    "    insert_list = []\n",
    "    # index as binary number\n",
    "    binary = '{0:02b}'.format(w)\n",
    "    # get qubit at digit in binary state (positions of qubits : q0, q1, q2, q3) (figuratively, not actually, we are in superposition after all)\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    # this_phase_gate = MCPhaseGate(value, 3, label=\"this_phase_gate\")\n",
    "    # qc.this_phase_gate(0, 1, 2, 3)\n",
    "    # perform conjugate transpose controlled phase shift\n",
    "    insert_list.append(cphase((-1) * control_params1[w])(*regular_qubits))\n",
    "    # \"undo\" the NOT-gates to get back to previous states = apply another not\n",
    "    for j in range(len(binary)):\n",
    "        if binary[j] == '0':\n",
    "            insert_list.append(X(regular_qubits[j]))\n",
    "    qc.append(insert_list, strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# apply Hadamard gate to all regular qubits\n",
    "qc.append(H.on_each(*regular_qubits), strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# apply X gate to all regular qubits\n",
    "qc.append(X.on_each(*regular_qubits), strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# collect combined state from all regular qubits with ancilla qubit using Toffoli-Gate\n",
    "# Toffoli-Gate does not work in TFQ -> implement decomposition (compare https://en.wikipedia.org/wiki/Toffoli_gate#/media/File:Qcircuit_ToffolifromCNOT.svg)\n",
    "qc.append([H(ancilla), CNOT(regular_qubits[1], ancilla), cirq.inverse(T(ancilla)), CNOT(regular_qubits[0], ancilla), T(ancilla), CNOT(regular_qubits[1], ancilla), cirq.inverse(T(ancilla)), CNOT(regular_qubits[0], ancilla), T(ancilla), T(regular_qubits[1]), H(ancilla), CNOT(regular_qubits[0], regular_qubits[1]), cirq.inverse(T(regular_qubits[1])), T(regular_qubits[0]), CNOT(regular_qubits[0], regular_qubits[1])], strategy=InsertStrategy.NEW_THEN_INLINE)\n",
    "# draw circuit\n",
    "SVGCircuit(qc)\n",
    "# end circuit\n",
    "\n",
    "# values to initialize the weights (?)\n",
    "np.random.seed(seed=69)\n",
    "int_values = np.random.rand((len(control_params1)))*np.pi\n",
    "\n",
    "measurement = [Z(ancilla)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define QPINN class\n",
    "class QPhysicsInformedNN(object):\n",
    "  def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu, control_params, control_params1, int_values, measurement):\n",
    "    # Keras model\n",
    "    \"\"\"self.u_model = tf.keras.Sequential()\n",
    "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
    "    self.u_model.add(tf.keras.layers.Lambda(\n",
    "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\"\"\"\n",
    "    self.unused = tf.keras.Input(shape=(), dtype=tf.dtypes.string, name=\"unused\")\n",
    "    self.inputs = tf.keras.layers.Input(shape=(layers[0],))\n",
    "    \n",
    "    def custom_layer(X):\n",
    "        return 2.0*(X - lb)/(ub - lb) - 1.0\n",
    "\n",
    "    self.outputs = tf.keras.layers.Lambda(custom_layer, name=\"lambda_layer\")(self.inputs)\n",
    "    \n",
    "    #self.outputs = tf.keras.layers.Lambda(lambda X: 2.0*(X - lb)/(ub - lb) - 1.0)(self.inputs)\n",
    "    for width in layers[1:]:\n",
    "        self.outputs = tf.keras.layers.Dense(width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal')(self.outputs)\n",
    "    #quantum layer\n",
    "    self.outputs = SplitBackpropQ(control_params, control_params1, int_values, measurement)([self.unused, self.outputs])\n",
    "    #generate model\n",
    "    self.u_model = tf.keras.Model(inputs=[self.unused, self.inputs], outputs=self.outputs)\n",
    "    \n",
    "    #inputs = tf.keras.Input(shape=(3,))\n",
    "    #x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "    #outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "    #model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \"\"\"\n",
    "    unused = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
    "    inputlayer = keras.Input(shape=(32,), name=\"inputlayer\")\n",
    "    x = layers.Dense(32, activation=\"relu\")(inputlayer)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(4, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    expectation = SplitBackpropQ(control_params, control_params1, int_values, measurement)([unused, x])\n",
    "    #expectation = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=[unused, inputlayer], outputs=expectation)\"\"\"\n",
    "    \n",
    "    \"\"\"for width in layers[1:]:\n",
    "        if width == 3:\n",
    "            self.u_model.add(qlayer)\n",
    "        else:\n",
    "            self.u_model.add(tf.keras.layers.Dense(\n",
    "              width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal'))\"\"\"\n",
    "\n",
    "    # Computing the sizes of weights/biases for future decomposition\n",
    "    self.sizes_w = []\n",
    "    self.sizes_b = []\n",
    "    for i, width in enumerate(layers):\n",
    "      if i != 1:\n",
    "        self.sizes_w.append(int(width * layers[1]))\n",
    "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
    "\n",
    "    self.nu = nu\n",
    "    self.optimizer = optimizer\n",
    "    self.logger = logger\n",
    "\n",
    "    self.dtype = tf.float32\n",
    "\n",
    "    #Â Separating the collocation coordinates\n",
    "    self.x_f = tf.convert_to_tensor(X_f[:, 0:1], dtype=self.dtype)\n",
    "    self.t_f = tf.convert_to_tensor(X_f[:, 1:2], dtype=self.dtype)\n",
    "    \n",
    "  # Defining custom loss\n",
    "  def __loss(self, u, u_pred):\n",
    "    f_pred = self.f_model()\n",
    "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
    "      tf.reduce_mean(tf.square(f_pred))\n",
    "\n",
    "  def __grad(self, X, u):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss_value = self.__loss(u, self.u_model(X))\n",
    "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
    "\n",
    "  def __wrap_training_variables(self):\n",
    "    var = self.u_model.trainable_variables\n",
    "    return var\n",
    "\n",
    "  # The actual PINN\n",
    "  def f_model(self):\n",
    "    # Using the new GradientTape paradigm of TF2.0,\n",
    "    # which keeps track of operations to get the gradient at runtime\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "      # Watching the two inputs weâll need later, x and t\n",
    "      tape.watch(self.x_f)\n",
    "      tape.watch(self.t_f)\n",
    "      # Packing together the inputs\n",
    "      X_f = tf.stack([self.x_f[:,0], self.t_f[:,0]], axis=1)\n",
    "\n",
    "      # Getting the prediction\n",
    "      u = self.u_model(X_f)\n",
    "      # Deriving INSIDE the tape (since weâll need the x derivative of this later, u_xx)\n",
    "      u_x = tape.gradient(u, self.x_f)\n",
    "    \n",
    "    # Getting the other derivatives\n",
    "    u_xx = tape.gradient(u_x, self.x_f)\n",
    "    u_t = tape.gradient(u, self.t_f)\n",
    "\n",
    "    # Letting the tape go\n",
    "    del tape\n",
    "\n",
    "    nu = self.get_params(numpy=True)\n",
    "\n",
    "    # Buidling the PINNs\n",
    "    return u_t + u*u_x - nu*u_xx\n",
    "\n",
    "  def get_params(self, numpy=False):\n",
    "    return self.nu\n",
    "\n",
    "  def get_weights(self):\n",
    "    w = []\n",
    "    for layer in self.u_model.layers[1:]:\n",
    "      weights_biases = layer.get_weights()\n",
    "      weights = weights_biases[0].flatten()\n",
    "      biases = weights_biases[1]\n",
    "      w.extend(weights)\n",
    "      w.extend(biases)\n",
    "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
    "\n",
    "  def set_weights(self, w):\n",
    "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
    "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
    "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
    "      weights = w[start_weights:end_weights]\n",
    "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
    "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
    "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
    "      weights_biases = [weights, biases]\n",
    "      layer.set_weights(weights_biases)\n",
    "\n",
    "  def summary(self):\n",
    "    return self.u_model.summary()\n",
    "\n",
    "  # The training function\n",
    "  def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
    "    self.logger.log_train_start(self)\n",
    "\n",
    "    # Creating the tensors\n",
    "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
    "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
    "\n",
    "    self.logger.log_train_opt(\"Adam\")\n",
    "    for epoch in range(tf_epochs):\n",
    "      # Optimization step\n",
    "      loss_value, grads = self.__grad(X_u, u)\n",
    "      self.optimizer.apply_gradients(zip(grads, self.__wrap_training_variables()))\n",
    "      self.logger.log_train_epoch(epoch, loss_value)\n",
    "    \n",
    "    self.logger.log_train_opt(\"LBFGS\")\n",
    "    def loss_and_flat_grad(w):\n",
    "      with tf.GradientTape() as tape:\n",
    "        self.set_weights(w)\n",
    "        loss_value = self.__loss(u, self.u_model(X_u))\n",
    "      grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
    "      grad_flat = []\n",
    "      for g in grad:\n",
    "        grad_flat.append(tf.reshape(g, [-1]))\n",
    "      grad_flat =  tf.concat(grad_flat, 0)\n",
    "      return loss_value, grad_flat\n",
    "    # tfp.optimizer.lbfgs_minimize(\n",
    "    #   loss_and_flat_grad,\n",
    "    #   initial_position=self.get_weights(),\n",
    "    #   num_correction_pairs=nt_config.nCorrection,\n",
    "    #   max_iterations=nt_config.maxIter,\n",
    "    #   f_relative_tolerance=nt_config.tolFun,\n",
    "    #   tolerance=nt_config.tolFun,\n",
    "    #   parallel_iterations=6)\n",
    "    \"\"\"lbfgs(loss_and_flat_grad,\n",
    "      self.get_weights(),\n",
    "      nt_config, Struct(), True,\n",
    "      lambda epoch, loss, is_iter:\n",
    "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\"\"\"\n",
    "\n",
    "    self.logger.log_train_end(tf_epochs + nt_config.maxIter)\n",
    "\n",
    "  def predict(self, X_star):\n",
    "    u_star = self.u_model(X_star)\n",
    "    f_star = self.f_model()\n",
    "    return u_star, f_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters quantum PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size on the solution u\n",
    "N_u = 50\n",
    "# Collocation points size, where weâll check for f = 0\n",
    "N_f = 10000\n",
    "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
    "\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "tf_epochs = 1000\n",
    "tf_optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate=0.3,\n",
    "  beta_1=0.99,\n",
    "  epsilon=1e-1)\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "nt_epochs = 500 # 2000\n",
    "nt_config = Struct()\n",
    "nt_config.learningRate = 0.8\n",
    "nt_config.maxIter = nt_epochs\n",
    "nt_config.nCorrection = 50\n",
    "nt_config.tolFun = 1.0 * np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: False\n",
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_layer (Lambda)           (None, 2)            0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 20)           60          lambda_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 20)           420         dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 20)           420         dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 20)           420         dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 20)           420         dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 20)           420         dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 20)           420         dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 20)           420         dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unused (InputLayer)             [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 1)            21          dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "split_backprop_q_2 (SplitBackpr (None, 1)            4           unused[0][0]                     \n",
      "                                                                 dense_121[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,025\n",
      "Trainable params: 3,025\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "ââ Starting Adam optimization ââ\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Cast float to string is not supported [Op:Cast]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-4b7363320dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_star\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mqpinn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_u_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-42a82fbdd0e7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_u, u, tf_epochs, nt_config)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;31m# Optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrap_training_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-42a82fbdd0e7>\u001b[0m in \u001b[0;36m__grad\u001b[0;34m(self, X, u)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrap_training_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0mtensor_usage_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_usage_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conform_to_reference_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m       \u001b[0mx_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtensor_usage_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_conform_to_reference_input\u001b[0;34m(self, tensor, ref_input)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;31m# Dtype casting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompositeTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m       \u001b[0;31m# Dtype casting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    920\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1856\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Cast float to string is not supported [Op:Cast]"
     ]
    }
   ],
   "source": [
    "# Getting the data\n",
    "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
    "x, t, X, T, Exact_u, X_star, u_star, \\\n",
    "  X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
    "\n",
    "# Creating the model and training\n",
    "logger = Logger(frequency=10)\n",
    "nu=0.01/np.pi\n",
    "qpinn = QPhysicsInformedNN(layers, tf_optimizer, logger, X_f, ub, lb, nu, control_params, control_params1, int_values, measurement)\n",
    "def error():\n",
    "  u_pred, _ = qpinn.predict(X_star)\n",
    "  return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "logger.set_error_fn(error)\n",
    "qpinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
    "\n",
    "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
    "u_pred, f_pred = qpinn.predict(X_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 388.543x264.146 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_inf_cont_results(X_star, u_pred.numpy().flatten(), X_u_train, u_train,\n",
    "  Exact_u, X, T, x, t, file = \"qplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "A1Mj-RBCn8MZ",
    "GkimJNtepkKi",
    "dOPzdkKsJzA4",
    "OTxvp1nJGDeb",
    "QGd5zVtoxAqt",
    "bXtJ5GiaxAqw",
    "fGrMDRc3w1ex",
    "rRGW4IW0w1e0"
   ],
   "name": "PINNs for 1D Burgers Equation (TF2.0).ipynb",
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
