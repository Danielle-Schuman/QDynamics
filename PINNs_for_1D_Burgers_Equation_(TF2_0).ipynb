{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1Mj-RBCn8MZ"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al80f-lPoJjh"
   },
   "source": [
    "## Getting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "r3iHOMsdnNiq",
    "outputId": "48316653-e273-470c-daa6-f04891dde84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klone nach 'PINNs' ...\n",
      "remote: Enumerating objects: 741, done.\u001b[K\n",
      "remote: Total 741 (delta 0), reused 0 (delta 0), pack-reused 741\u001b[K\n",
      "Empfange Objekte: 100% (741/741), 474.47 MiB | 10.68 MiB/s, Fertig.\n",
      "Löse Unterschiede auf: 100% (66/66), Fertig.\n",
      "Aktualisiere Dateien: 100% (561/561), Fertig.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/maziarraissi/PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gtoc_dXgoOZq"
   },
   "source": [
    "## Setting up modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNMtDjXkFHaN"
   },
   "source": [
    "TeX packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TaZCKcDsEVRP",
    "outputId": "be5e2e31-f422-4c58-a821-0d7f7a38af9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get -qq install texlive-fonts-recommended texlive-fonts-extra dvipng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Otc4Ap7qFMlf"
   },
   "source": [
    "Pip modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "collapsed": true,
    "id": "srpq4aQNoQ1E",
    "outputId": "78582ecd-9664-4784-ab57-ef8276779e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyDOE\n",
      "  Using cached pyDOE-0.3.8-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.4.1)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.3.1-cp37-cp37m-macosx_10_9_x86_64.whl (165.1 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.19.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyDOE) (1.18.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow) (46.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.19.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Installing collected packages: tensorflow, pyDOE\n",
      "Successfully installed pyDOE-0.3.8 tensorflow-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow pyDOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksKujMvUFRNW"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZEDn2fqlqctT",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "# Manually making sure the numpy random seeds are \"the same\" on all devices\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODGREPvZpqUz"
   },
   "source": [
    "## Utilities: Data preparation, logger class and plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FgPvqJiYFnYG",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyDOE import lhs\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
    "repoPath = os.path.join(\".\", \"PINNs\")\n",
    "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
    "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
    "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
    "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")\n",
    "\n",
    "sys.path.insert(0, utilsPath)\n",
    "from plotting import newfig, savefig\n",
    "\n",
    "# prepare data\n",
    "def prep_data(path, N_u=None, N_f=None, N_n=None, q=None, ub=None, lb=None, noise=0.0, idx_t_0=None, idx_t_1=None, N_0=None, N_1=None):\n",
    "    # Reading external data [t is 100x1, usol is 256x100 (solution), x is 256x1]\n",
    "    data = scipy.io.loadmat(path)\n",
    "\n",
    "    # Flatten makes [[]] into [], [:,None] makes it a column vector\n",
    "    t = data['t'].flatten()[:,None] # T x 1\n",
    "    x = data['x'].flatten()[:,None] # N x 1\n",
    "\n",
    "    # Keeping the 2D data for the solution data (real() is maybe to make it float by default, in case of zeroes)\n",
    "    Exact_u = np.real(data['usol']).T # T x N\n",
    "\n",
    "    if N_n != None and q != None and ub != None and lb != None and idx_t_0 != None and idx_t_1 != None:\n",
    "      dt = t[idx_t_1] - t[idx_t_0]\n",
    "      idx_x = np.random.choice(Exact_u.shape[1], N_n, replace=False) \n",
    "      x_0 = x[idx_x,:]\n",
    "      u_0 = Exact_u[idx_t_0:idx_t_0+1,idx_x].T\n",
    "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
    "        \n",
    "      # Boudanry data\n",
    "      x_1 = np.vstack((lb, ub))\n",
    "      \n",
    "      # Test data\n",
    "      x_star = x\n",
    "      u_star = Exact_u[idx_t_1,:]\n",
    "\n",
    "      # Load IRK weights\n",
    "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
    "      IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
    "      IRK_times = tmp[q**2+q:]\n",
    "\n",
    "      return x, t, dt, Exact_u, x_0, u_0, x_1, x_star, u_star, IRK_weights, IRK_times\n",
    "\n",
    "    # Meshing x and t in 2D (256,100)\n",
    "    X, T = np.meshgrid(x,t)\n",
    "\n",
    "    # Preparing the inputs x and t (meshed as X, T) for predictions in one single array, as X_star\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "    # Preparing the testing u_star\n",
    "    u_star = Exact_u.flatten()[:,None]\n",
    "                \n",
    "    # Noiseless data TODO: add support for noisy data    \n",
    "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
    "    X_u_train = X_star[idx,:]\n",
    "    u_train = u_star[idx,:]\n",
    "\n",
    "    if N_0 != None and N_1 != None:\n",
    "      Exact_u = Exact_u.T\n",
    "      idx_x = np.random.choice(Exact_u.shape[0], N_0, replace=False)\n",
    "      x_0 = x[idx_x,:]\n",
    "      u_0 = Exact_u[idx_x,idx_t_0][:,None]\n",
    "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
    "          \n",
    "      idx_x = np.random.choice(Exact_u.shape[0], N_1, replace=False)\n",
    "      x_1 = x[idx_x,:]\n",
    "      u_1 = Exact_u[idx_x,idx_t_1][:,None]\n",
    "      u_1 = u_1 + noise*np.std(u_1)*np.random.randn(u_1.shape[0], u_1.shape[1])\n",
    "      \n",
    "      dt = np.asscalar(t[idx_t_1] - t[idx_t_0])        \n",
    "      q = int(np.ceil(0.5*np.log(np.finfo(float).eps)/np.log(dt)))\n",
    "\n",
    "      # Load IRK weights\n",
    "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
    "      weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
    "      IRK_alpha = weights[0:-1,:]\n",
    "      IRK_beta = weights[-1:,:] \n",
    "      return x_0, u_0, x_1, u_1, x, t, dt, q, Exact_u, IRK_alpha, IRK_beta\n",
    "\n",
    "    if N_f == None:\n",
    "      lb = X_star.min(axis=0)\n",
    "      ub = X_star.max(axis=0) \n",
    "      return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, ub, lb\n",
    "\n",
    "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
    "    lb = X_star.min(axis=0)\n",
    "    ub = X_star.max(axis=0) \n",
    "    # Getting the initial conditions (t=0)\n",
    "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "    uu1 = Exact_u[0:1,:].T\n",
    "    # Getting the lowest boundary conditions (x=-1) \n",
    "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "    uu2 = Exact_u[:,0:1]\n",
    "    # Getting the highest boundary conditions (x=1) \n",
    "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "    uu3 = Exact_u[:,-1:]\n",
    "    # Stacking them in multidimensional tensors for training (X_u_train is for now the continuous boundaries)\n",
    "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "    u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "    # Generating the x and t collocation points for f, with each having a N_f size\n",
    "    # We pointwise add and multiply to spread the LHS over the 2D domain\n",
    "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "\n",
    "    # Generating a uniform random sample from ints between 0, and the size of x_u_train, of size N_u (initial data size) and without replacement (unique)\n",
    "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "    # Getting the corresponding X_u_train (which is now scarce boundary/initial coordinates)\n",
    "    X_u_train = X_u_train[idx,:]\n",
    "    # Getting the corresponding u_train\n",
    "    u_train = u_train [idx,:]\n",
    "\n",
    "    return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, X_f_train, ub, lb\n",
    "\n",
    "# define logger class\n",
    "class Logger(object):\n",
    "  def __init__(self, frequency=10):\n",
    "    print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "    print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "    print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
    "\n",
    "    self.start_time = time.time()\n",
    "    self.frequency = frequency\n",
    "\n",
    "  def __get_elapsed(self):\n",
    "    return datetime.fromtimestamp(time.time() - self.start_time).strftime(\"%M:%S\")\n",
    "\n",
    "  def __get_error_u(self):\n",
    "    return self.error_fn()\n",
    "\n",
    "  def set_error_fn(self, error_fn):\n",
    "    self.error_fn = error_fn\n",
    "  \n",
    "  def log_train_start(self, model):\n",
    "    print(\"\\nTraining started\")\n",
    "    print(\"================\")\n",
    "    self.model = model\n",
    "    print(self.model.summary())\n",
    "\n",
    "  def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
    "    if epoch % self.frequency == 0:\n",
    "      print(f\"{'nt_epoch' if is_iter else 'tf_epoch'} = {epoch:6d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  error = {self.__get_error_u():.4e}  \" + custom)\n",
    "\n",
    "  def log_train_opt(self, name):\n",
    "    # print(f\"tf_epoch =      0  elapsed = 00:00  loss = 2.7391e-01  error = 9.0843e-01\")\n",
    "    print(f\"—— Starting {name} optimization ——\")\n",
    "\n",
    "  def log_train_end(self, epoch, custom=\"\"):\n",
    "    print(\"==================\")\n",
    "    print(f\"Training finished (epoch {epoch}): duration = {self.__get_elapsed()}  error = {self.__get_error_u():.4e}  \" + custom)\n",
    "\n",
    "# for plotting\n",
    "def plot_inf_cont_results(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, file=None):\n",
    "\n",
    "  # Interpolating the results on the whole (x,t) domain.\n",
    "  # griddata(points, values, points at which to interpolate, method)\n",
    "  U_pred = griddata(X_star, u_pred, (X, T), method='cubic')\n",
    "\n",
    "  # Creating the figures\n",
    "  fig, ax = newfig(1.0, 1.1)\n",
    "  ax.axis('off')\n",
    "\n",
    "  ####### Row 0: u(t,x) ##################    \n",
    "  gs0 = gridspec.GridSpec(1, 2)\n",
    "  gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "  ax = plt.subplot(gs0[:, :])\n",
    "\n",
    "  h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
    "                origin='lower', aspect='auto')\n",
    "  divider = make_axes_locatable(ax)\n",
    "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "  fig.colorbar(h, cax=cax)\n",
    "\n",
    "  ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
    "\n",
    "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "  ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "  ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "  ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
    "\n",
    "  ax.set_xlabel('$t$')\n",
    "  ax.set_ylabel('$x$')\n",
    "  ax.legend(frameon=False, loc = 'best')\n",
    "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
    "\n",
    "  ####### Row 1: u(t,x) slices ##################    \n",
    "  gs1 = gridspec.GridSpec(1, 3)\n",
    "  gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "  ax = plt.subplot(gs1[0, 0])\n",
    "  ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "  ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "  ax.set_xlabel('$x$')\n",
    "  ax.set_ylabel('$u(t,x)$')    \n",
    "  ax.set_title('$t = 0.25$', fontsize = 10)\n",
    "  ax.axis('square')\n",
    "  ax.set_xlim([-1.1,1.1])\n",
    "  ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "  ax = plt.subplot(gs1[0, 1])\n",
    "  ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "  ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "  ax.set_xlabel('$x$')\n",
    "  ax.set_ylabel('$u(t,x)$')\n",
    "  ax.axis('square')\n",
    "  ax.set_xlim([-1.1,1.1])\n",
    "  ax.set_ylim([-1.1,1.1])\n",
    "  ax.set_title('$t = 0.50$', fontsize = 10)\n",
    "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "\n",
    "  ax = plt.subplot(gs1[0, 2])\n",
    "  ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "  ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "  ax.set_xlabel('$x$')\n",
    "  ax.set_ylabel('$u(t,x)$')\n",
    "  ax.axis('square')\n",
    "  ax.set_xlim([-1.1,1.1])\n",
    "  ax.set_ylim([-1.1,1.1])    \n",
    "  ax.set_title('$t = 0.75$', fontsize = 10)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  if file != None:\n",
    "    fig.savefig(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Azv7DZp0M-"
   },
   "source": [
    "## Define custom lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OjvMe1Avpvh9",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/yaroslavvb/stuff/blob/master/eager_lbfgs/eager_lbfgs.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Time tracking functions\n",
    "global_time_list = []\n",
    "global_last_time = 0\n",
    "def reset_time():\n",
    "  global global_time_list, global_last_time\n",
    "  global_time_list = []\n",
    "  global_last_time = time.perf_counter()\n",
    "  \n",
    "def record_time():\n",
    "  global global_last_time, global_time_list\n",
    "  new_time = time.perf_counter()\n",
    "  global_time_list.append(new_time - global_last_time)\n",
    "  global_last_time = time.perf_counter()\n",
    "  #print(\"step: %.2f\"%(global_time_list[-1]*1000))\n",
    "\n",
    "def last_time():\n",
    "  \"\"\"Returns last interval records in millis.\"\"\"\n",
    "  global global_last_time, global_time_list\n",
    "  if global_time_list:\n",
    "    return 1000 * global_time_list[-1]\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def dot(a, b):\n",
    "  \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
    "  return tf.reduce_sum(a*b)\n",
    "\n",
    "def verbose_func(s):\n",
    "  print(s)\n",
    "\n",
    "final_loss = None\n",
    "times = []\n",
    "def lbfgs(opfunc, x, config, state, do_verbose, log_fn):\n",
    "  \"\"\"port of lbfgs.lua, using TensorFlow eager mode.\n",
    "  \"\"\"\n",
    "\n",
    "  if config.maxIter == 0:\n",
    "    return\n",
    "\n",
    "  global final_loss, times\n",
    "  \n",
    "  maxIter = config.maxIter\n",
    "  maxEval = config.maxEval or maxIter*1.25\n",
    "  tolFun = config.tolFun or 1e-5\n",
    "  tolX = config.tolX or 1e-19\n",
    "  nCorrection = config.nCorrection or 100\n",
    "  lineSearch = config.lineSearch\n",
    "  lineSearchOpts = config.lineSearchOptions\n",
    "  learningRate = config.learningRate or 1\n",
    "  isverbose = config.verbose or False\n",
    "\n",
    "  # verbose function\n",
    "  if isverbose:\n",
    "    verbose = verbose_func\n",
    "  else:\n",
    "    verbose = lambda x: None\n",
    "\n",
    "    # evaluate initial f(x) and df/dx\n",
    "  f, g = opfunc(x)\n",
    "\n",
    "  f_hist = [f]\n",
    "  currentFuncEval = 1\n",
    "  state.funcEval = state.funcEval + 1\n",
    "  p = g.shape[0]\n",
    "\n",
    "  # check optimality of initial point\n",
    "  tmp1 = tf.abs(g)\n",
    "  if tf.reduce_sum(tmp1) <= tolFun:\n",
    "    verbose(\"optimality condition below tolFun\")\n",
    "    return x, f_hist\n",
    "\n",
    "  # optimize for a max of maxIter iterations\n",
    "  nIter = 0\n",
    "  times = []\n",
    "  while nIter < maxIter:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # keep track of nb of iterations\n",
    "    nIter = nIter + 1\n",
    "    state.nIter = state.nIter + 1\n",
    "\n",
    "    ############################################################\n",
    "    ## compute gradient descent direction\n",
    "    ############################################################\n",
    "    if state.nIter == 1:\n",
    "      d = -g\n",
    "      old_dirs = []\n",
    "      old_stps = []\n",
    "      Hdiag = 1\n",
    "    else:\n",
    "      # do lbfgs update (update memory)\n",
    "      y = g - g_old\n",
    "      s = d*t\n",
    "      ys = dot(y, s)\n",
    "      \n",
    "      if ys > 1e-10:\n",
    "        # updating memory\n",
    "        if len(old_dirs) == nCorrection:\n",
    "          # shift history by one (limited-memory)\n",
    "          del old_dirs[0]\n",
    "          del old_stps[0]\n",
    "\n",
    "        # store new direction/step\n",
    "        old_dirs.append(s)\n",
    "        old_stps.append(y)\n",
    "\n",
    "        # update scale of initial Hessian approximation\n",
    "        Hdiag = ys/dot(y, y)\n",
    "\n",
    "      # compute the approximate (L-BFGS) inverse Hessian \n",
    "      # multiplied by the gradient\n",
    "      k = len(old_dirs)\n",
    "\n",
    "      # need to be accessed element-by-element, so don't re-type tensor:\n",
    "      ro = [0]*nCorrection\n",
    "      for i in range(k):\n",
    "        ro[i] = 1/dot(old_stps[i], old_dirs[i])\n",
    "        \n",
    "\n",
    "      # iteration in L-BFGS loop collapsed to use just one buffer\n",
    "      # need to be accessed element-by-element, so don't re-type tensor:\n",
    "      al = [0]*nCorrection\n",
    "\n",
    "      q = -g\n",
    "      for i in range(k-1, -1, -1):\n",
    "        al[i] = dot(old_dirs[i], q) * ro[i]\n",
    "        q = q - al[i]*old_stps[i]\n",
    "\n",
    "      # multiply by initial Hessian\n",
    "      r = q*Hdiag\n",
    "      for i in range(k):\n",
    "        be_i = dot(old_stps[i], r) * ro[i]\n",
    "        r += (al[i]-be_i)*old_dirs[i]\n",
    "        \n",
    "      d = r\n",
    "      # final direction is in r/d (same object)\n",
    "\n",
    "    g_old = g\n",
    "    f_old = f\n",
    "    \n",
    "    ############################################################\n",
    "    ## compute step length\n",
    "    ############################################################\n",
    "    # directional derivative\n",
    "    gtd = dot(g, d)\n",
    "\n",
    "    # check that progress can be made along that direction\n",
    "    if gtd > -tolX:\n",
    "      verbose(\"Can not make progress along direction.\")\n",
    "      break\n",
    "\n",
    "    # reset initial guess for step size\n",
    "    if state.nIter == 1:\n",
    "      tmp1 = tf.abs(g)\n",
    "      t = min(1, 1/tf.reduce_sum(tmp1))\n",
    "    else:\n",
    "      t = learningRate\n",
    "\n",
    "\n",
    "    # optional line search: user function\n",
    "    lsFuncEval = 0\n",
    "    if lineSearch and isinstance(lineSearch) == types.FunctionType:\n",
    "      # perform line search, using user function\n",
    "      f,g,x,t,lsFuncEval = lineSearch(opfunc,x,t,d,f,g,gtd,lineSearchOpts)\n",
    "      f_hist.append(f)\n",
    "    else:\n",
    "      # no line search, simply move with fixed-step\n",
    "      x += t*d\n",
    "      \n",
    "      if nIter != maxIter:\n",
    "        # re-evaluate function only if not in last iteration\n",
    "        # the reason we do this: in a stochastic setting,\n",
    "        # no use to re-evaluate that function here\n",
    "        f, g = opfunc(x)\n",
    "        lsFuncEval = 1\n",
    "        f_hist.append(f)\n",
    "\n",
    "\n",
    "    # update func eval\n",
    "    currentFuncEval = currentFuncEval + lsFuncEval\n",
    "    state.funcEval = state.funcEval + lsFuncEval\n",
    "\n",
    "    ############################################################\n",
    "    ## check conditions\n",
    "    ############################################################\n",
    "    if nIter == maxIter:\n",
    "      break\n",
    "\n",
    "    if currentFuncEval >= maxEval:\n",
    "      # max nb of function evals\n",
    "      verbose('max nb of function evals')\n",
    "      break\n",
    "\n",
    "    tmp1 = tf.abs(g)\n",
    "    if tf.reduce_sum(tmp1) <=tolFun:\n",
    "      # check optimality\n",
    "      verbose('optimality condition below tolFun')\n",
    "      break\n",
    "    \n",
    "    tmp1 = tf.abs(d*t)\n",
    "    if tf.reduce_sum(tmp1) <= tolX:\n",
    "      # step size below tolX\n",
    "      verbose('step size below tolX')\n",
    "      break\n",
    "\n",
    "    if tf.abs(f-f_old) < tolX:\n",
    "      # function value changing less than tolX\n",
    "      verbose('function value changing less than tolX'+str(tf.abs(f-f_old)))\n",
    "      break\n",
    "\n",
    "    if do_verbose:\n",
    "      log_fn(nIter, f.numpy(), True)\n",
    "      #print(\"Step %3d loss %6.5f msec %6.3f\"%(nIter, f.numpy(), last_time()))\n",
    "      record_time()\n",
    "      times.append(last_time())\n",
    "\n",
    "    if nIter == maxIter - 1:\n",
    "      final_loss = f.numpy()\n",
    "\n",
    "\n",
    "  # save state\n",
    "  state.old_dirs = old_dirs\n",
    "  state.old_stps = old_stps\n",
    "  state.Hdiag = Hdiag\n",
    "  state.g_old = g_old\n",
    "  state.f_old = f_old\n",
    "  state.t = t\n",
    "  state.d = d\n",
    "\n",
    "  return x, f_hist, currentFuncEval\n",
    "\n",
    "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
    "class dummy(object):\n",
    "  pass\n",
    "\n",
    "class Struct(dummy):\n",
    "  def __getattribute__(self, key):\n",
    "    if key == '__dict__':\n",
    "      return super(dummy, self).__getattribute__('__dict__')\n",
    "    return self.__dict__.get(key, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOT-E8C4oAJN"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Qrt3ECzcLHp"
   },
   "source": [
    "Burger' Equation:\n",
    "$$u_t + u u_x - \\nu u_{xx} = 0$$\n",
    "\n",
    "With $x \\in [-1,1],\\quad t \\in [0,1],\\quad \\nu = (0.01/\\pi)$.\n",
    "\n",
    "And $u(0,x) = -\\sin(\\pi x),\\quad u(t,-1) = u(t,1) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8CHqrpafela"
   },
   "source": [
    "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
    "$$f := u_t + u u_x - \\nu u_{xx}.$$\n",
    "\n",
    "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
    "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_f}|f(t_f^i,x_f^i)|^2,$$\n",
    "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ and $\\{t_f^i, x_f^i\\}_{i=1}^{N_f}$ respectively the initial/boundary data on $u(t,x)$ and collocations points for $f(t,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9Ko6L87J2v_"
   },
   "source": [
    "### Hyperparameters for the classical PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jwWhiecUqbAo",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Data size on the solution u\n",
    "N_u = 50\n",
    "# Collocation points size, where we’ll check for f = 0\n",
    "N_f = 10000\n",
    "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
    "\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "#layers = [2, 20, 2, 3, 2, 20, 1]\n",
    "\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "tf_epochs = 100\n",
    "tf_optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate=0.1,\n",
    "  beta_1=0.99,\n",
    "  epsilon=1e-1)\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "nt_epochs = 500 #1000-2000 way more accurate but this is quicker ...\n",
    "nt_config = Struct()\n",
    "nt_config.learningRate = 0.8\n",
    "nt_config.maxIter = nt_epochs\n",
    "nt_config.nCorrection = 50\n",
    "nt_config.tolFun = 1.0 * np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkimJNtepkKi"
   },
   "source": [
    "## PINN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KVm9UCvvlyY_"
   },
   "outputs": [],
   "source": [
    "class PhysicsInformedNN(object):\n",
    "  def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu):\n",
    "    # Descriptive Sequential Keras model [2, 20, …, 20, 1]\n",
    "    self.u_model = tf.keras.Sequential()\n",
    "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
    "    self.u_model.add(tf.keras.layers.Lambda(\n",
    "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
    "    for width in layers[1:]: # add dense layers\n",
    "      self.u_model.add(tf.keras.layers.Dense(\n",
    "              width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal'))\n",
    "\n",
    "    # Computing the sizes of weights/biases for future decomposition\n",
    "    self.sizes_w = []\n",
    "    self.sizes_b = []\n",
    "    for i, width in enumerate(layers):\n",
    "      if i != 1:\n",
    "        self.sizes_w.append(int(width * layers[1]))\n",
    "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
    "\n",
    "    self.nu = nu\n",
    "    self.optimizer = optimizer\n",
    "    self.logger = logger\n",
    "\n",
    "    self.dtype = tf.float32\n",
    "\n",
    "    # Separating the collocation coordinates\n",
    "    self.x_f = tf.convert_to_tensor(X_f[:, 0:1], dtype=self.dtype)\n",
    "    self.t_f = tf.convert_to_tensor(X_f[:, 1:2], dtype=self.dtype)\n",
    "    \n",
    "  # Defining custom loss\n",
    "  def __loss(self, u, u_pred):\n",
    "    f_pred = self.f_model()\n",
    "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
    "      tf.reduce_mean(tf.square(f_pred))\n",
    "\n",
    "  def __grad(self, X, u):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss_value = self.__loss(u, self.u_model(X))\n",
    "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
    "\n",
    "  def __wrap_training_variables(self):\n",
    "    var = self.u_model.trainable_variables\n",
    "    return var\n",
    "\n",
    "  # The actual PINN\n",
    "  def f_model(self):\n",
    "    # Using the new GradientTape paradigm of TF2.0,\n",
    "    # which keeps track of operations to get the gradient at runtime\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "      # Watching the two inputs we’ll need later, x and t\n",
    "      tape.watch(self.x_f)\n",
    "      tape.watch(self.t_f)\n",
    "      # Packing together the inputs\n",
    "      X_f = tf.stack([self.x_f[:,0], self.t_f[:,0]], axis=1)\n",
    "\n",
    "      # Getting the prediction\n",
    "      u = self.u_model(X_f)\n",
    "      # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
    "      u_x = tape.gradient(u, self.x_f)\n",
    "    \n",
    "    # Getting the other derivatives\n",
    "    u_xx = tape.gradient(u_x, self.x_f)\n",
    "    u_t = tape.gradient(u, self.t_f)\n",
    "\n",
    "    # Letting the tape go\n",
    "    del tape\n",
    "\n",
    "    nu = self.get_params(numpy=True)\n",
    "\n",
    "    # Buidling the PINNs\n",
    "    return u_t + u*u_x - nu*u_xx\n",
    "\n",
    "  def get_params(self, numpy=False):\n",
    "    return self.nu\n",
    "\n",
    "  def get_weights(self):\n",
    "    w = []\n",
    "    for layer in self.u_model.layers[1:]:\n",
    "      weights_biases = layer.get_weights()\n",
    "      weights = weights_biases[0].flatten()\n",
    "      biases = weights_biases[1]\n",
    "      w.extend(weights)\n",
    "      w.extend(biases)\n",
    "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
    "\n",
    "  def set_weights(self, w):\n",
    "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
    "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
    "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
    "      weights = w[start_weights:end_weights]\n",
    "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
    "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
    "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
    "      weights_biases = [weights, biases]\n",
    "      layer.set_weights(weights_biases)\n",
    "\n",
    "  def summary(self):\n",
    "    return self.u_model.summary()\n",
    "\n",
    "  # The training function\n",
    "  def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
    "    self.logger.log_train_start(self)\n",
    "\n",
    "    # Creating the tensors\n",
    "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
    "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
    "\n",
    "    self.logger.log_train_opt(\"Adam\")\n",
    "    for epoch in range(tf_epochs):\n",
    "      # Optimization step\n",
    "      loss_value, grads = self.__grad(X_u, u)\n",
    "      self.optimizer.apply_gradients(zip(grads, self.__wrap_training_variables()))\n",
    "      self.logger.log_train_epoch(epoch, loss_value)\n",
    "    \n",
    "    self.logger.log_train_opt(\"LBFGS\")\n",
    "    def loss_and_flat_grad(w):\n",
    "      with tf.GradientTape() as tape:\n",
    "        self.set_weights(w)\n",
    "        loss_value = self.__loss(u, self.u_model(X_u))\n",
    "      grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
    "      grad_flat = []\n",
    "      for g in grad:\n",
    "        grad_flat.append(tf.reshape(g, [-1]))\n",
    "      grad_flat =  tf.concat(grad_flat, 0)\n",
    "      return loss_value, grad_flat\n",
    "    # tfp.optimizer.lbfgs_minimize(\n",
    "    #   loss_and_flat_grad,\n",
    "    #   initial_position=self.get_weights(),\n",
    "    #   num_correction_pairs=nt_config.nCorrection,\n",
    "    #   max_iterations=nt_config.maxIter,\n",
    "    #   f_relative_tolerance=nt_config.tolFun,\n",
    "    #   tolerance=nt_config.tolFun,\n",
    "    #   parallel_iterations=6)\n",
    "    \"\"\"lbfgs(loss_and_flat_grad,\n",
    "      self.get_weights(),\n",
    "      nt_config, Struct(), True,\n",
    "      lambda epoch, loss, is_iter:\n",
    "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\"\"\"\n",
    "\n",
    "    self.logger.log_train_end(tf_epochs + nt_config.maxIter)\n",
    "\n",
    "  def predict(self, X_star):\n",
    "    u_star = self.u_model(X_star)\n",
    "    f_star = self.f_model()\n",
    "    return u_star, f_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FzMd65dpoHo"
   },
   "source": [
    "## Training and plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SEKkpHvApf46",
    "lines_to_next_cell": 2,
    "outputId": "8a6c27ef-8be5-431b-ab60-c4ddd6edb429",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: False\n",
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "lambda_layer (Lambda)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,021\n",
      "Trainable params: 3,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "—— Starting Adam optimization ——\n",
      "tf_epoch =      0  elapsed = 00:00  loss = 5.5133e-01  error = 9.5844e-01  \n",
      "tf_epoch =     10  elapsed = 00:03  loss = 2.6452e-01  error = 9.3412e-01  \n",
      "tf_epoch =     20  elapsed = 00:06  loss = 2.2908e-01  error = 7.8812e-01  \n",
      "tf_epoch =     30  elapsed = 00:08  loss = 2.0818e-01  error = 8.1507e-01  \n",
      "tf_epoch =     40  elapsed = 00:11  loss = 2.0806e-01  error = 8.1258e-01  \n",
      "tf_epoch =     50  elapsed = 00:13  loss = 1.9113e-01  error = 6.1637e-01  \n",
      "tf_epoch =     60  elapsed = 00:15  loss = 1.7994e-01  error = 7.1227e-01  \n",
      "tf_epoch =     70  elapsed = 00:17  loss = 1.7349e-01  error = 6.3453e-01  \n",
      "tf_epoch =     80  elapsed = 00:19  loss = 1.7529e-01  error = 6.4012e-01  \n",
      "tf_epoch =     90  elapsed = 00:22  loss = 1.7963e-01  error = 7.4018e-01  \n",
      "—— Starting LBFGS optimization ——\n",
      "==================\n",
      "Training finished (epoch 600): duration = 00:24  error = 6.4783e-01  \n"
     ]
    }
   ],
   "source": [
    "# Getting the data\n",
    "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
    "x, t, X, T, Exact_u, X_star, u_star, \\\n",
    "  X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
    "\n",
    "# Creating the model and training\n",
    "logger = Logger(frequency=10)\n",
    "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, X_f, ub, lb, nu=0.01/np.pi)\n",
    "def error():\n",
    "  u_pred, _ = pinn.predict(X_star)\n",
    "  return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "logger.set_error_fn(error)\n",
    "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
    "\n",
    "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
    "u_pred, f_pred = pinn.predict(X_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "Wf1QXaK5PlUh",
    "lines_to_next_cell": 0,
    "outputId": "7c9c2826-ba07-433a-ab68-73cd0f7ea2e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 388.543x264.146 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_inf_cont_results(X_star, u_pred.numpy().flatten(), X_u_train, u_train,\n",
    "  Exact_u, X, T, x, t, file = \"plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-3.1513e-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maxls pennylane try, does not work unfortunately\n",
    "import pennylane as qml\n",
    "\n",
    "\n",
    "n_qubits = 2\n",
    "dev = qml.device(\"default.qubit.tf\", wires=n_qubits) # \"lightning.qubit\" fast, C++ device\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1))\n",
    "\n",
    "weight_shapes = {\"weights\": (3, n_qubits, 3)}\n",
    "\n",
    "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define QPINN class\n",
    "class QPhysicsInformedNN(object):\n",
    "  def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu):\n",
    "    # Descriptive Keras model [2, 20, …, 20, 1]\n",
    "    \"\"\"self.u_model = tf.keras.Sequential()\n",
    "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
    "    self.u_model.add(tf.keras.layers.Lambda(\n",
    "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\"\"\"\n",
    "    \n",
    "    self.inputs =tf.keras.layers.Input(shape=(layers[0],))\n",
    "    \n",
    "    def custom_layer(X):\n",
    "        return 2.0*(X - lb)/(ub - lb) - 1.0\n",
    "\n",
    "    self.outputs = tf.keras.layers.Lambda(custom_layer, name=\"lambda_layer\")(self.inputs)\n",
    "    \n",
    "    #self.outputs = tf.keras.layers.Lambda(lambda X: 2.0*(X - lb)/(ub - lb) - 1.0)(self.inputs)\n",
    "    for width in layers[1:]:\n",
    "        self.outputs = tf.keras.layers.Dense(width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal')(self.outputs)\n",
    "    self.u_model = tf.keras.Model(inputs=self.inputs, outputs=self.outputs)\n",
    "    \n",
    "    #inputs = tf.keras.Input(shape=(3,))\n",
    "    #x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "    #outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "    #model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \"\"\"\n",
    "    # This is needed because of Note here:\n",
    "    # https://www.tensorflow.org/quantum/api_docs/python/tfq/layers/Expectation\n",
    "    unused = tf.keras.Input(shape=(), dtype=tf.dtypes.string)\n",
    "\n",
    "    x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(4, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    expectation = SplitBackpropQ(control_params, control_params1, int_values, measurement)([unused, x])\n",
    "    #expectation = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=[unused, all_inputs], outputs=expectation)\"\"\"\n",
    "    \n",
    "    \"\"\"for width in layers[1:]:\n",
    "        if width == 3:\n",
    "            self.u_model.add(qlayer)\n",
    "        else:\n",
    "            self.u_model.add(tf.keras.layers.Dense(\n",
    "              width, activation=tf.nn.tanh,\n",
    "              kernel_initializer='glorot_normal'))\"\"\"\n",
    "\n",
    "    # Computing the sizes of weights/biases for future decomposition\n",
    "    self.sizes_w = []\n",
    "    self.sizes_b = []\n",
    "    for i, width in enumerate(layers):\n",
    "      if i != 1:\n",
    "        self.sizes_w.append(int(width * layers[1]))\n",
    "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
    "\n",
    "    self.nu = nu\n",
    "    self.optimizer = optimizer\n",
    "    self.logger = logger\n",
    "\n",
    "    self.dtype = tf.float32\n",
    "\n",
    "    # Separating the collocation coordinates\n",
    "    self.x_f = tf.convert_to_tensor(X_f[:, 0:1], dtype=self.dtype)\n",
    "    self.t_f = tf.convert_to_tensor(X_f[:, 1:2], dtype=self.dtype)\n",
    "    \n",
    "  # Defining custom loss\n",
    "  def __loss(self, u, u_pred):\n",
    "    f_pred = self.f_model()\n",
    "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
    "      tf.reduce_mean(tf.square(f_pred))\n",
    "\n",
    "  def __grad(self, X, u):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss_value = self.__loss(u, self.u_model(X))\n",
    "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
    "\n",
    "  def __wrap_training_variables(self):\n",
    "    var = self.u_model.trainable_variables\n",
    "    return var\n",
    "\n",
    "  # The actual PINN\n",
    "  def f_model(self):\n",
    "    # Using the new GradientTape paradigm of TF2.0,\n",
    "    # which keeps track of operations to get the gradient at runtime\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "      # Watching the two inputs we’ll need later, x and t\n",
    "      tape.watch(self.x_f)\n",
    "      tape.watch(self.t_f)\n",
    "      # Packing together the inputs\n",
    "      X_f = tf.stack([self.x_f[:,0], self.t_f[:,0]], axis=1)\n",
    "\n",
    "      # Getting the prediction\n",
    "      u = self.u_model(X_f)\n",
    "      # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
    "      u_x = tape.gradient(u, self.x_f)\n",
    "    \n",
    "    # Getting the other derivatives\n",
    "    u_xx = tape.gradient(u_x, self.x_f)\n",
    "    u_t = tape.gradient(u, self.t_f)\n",
    "\n",
    "    # Letting the tape go\n",
    "    del tape\n",
    "\n",
    "    nu = self.get_params(numpy=True)\n",
    "\n",
    "    # Buidling the PINNs\n",
    "    return u_t + u*u_x - nu*u_xx\n",
    "\n",
    "  def get_params(self, numpy=False):\n",
    "    return self.nu\n",
    "\n",
    "  def get_weights(self):\n",
    "    w = []\n",
    "    for layer in self.u_model.layers[1:]:\n",
    "      weights_biases = layer.get_weights()\n",
    "      weights = weights_biases[0].flatten()\n",
    "      biases = weights_biases[1]\n",
    "      w.extend(weights)\n",
    "      w.extend(biases)\n",
    "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
    "\n",
    "  def set_weights(self, w):\n",
    "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
    "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
    "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
    "      weights = w[start_weights:end_weights]\n",
    "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
    "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
    "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
    "      weights_biases = [weights, biases]\n",
    "      layer.set_weights(weights_biases)\n",
    "\n",
    "  def summary(self):\n",
    "    return self.u_model.summary()\n",
    "\n",
    "  # The training function\n",
    "  def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
    "    self.logger.log_train_start(self)\n",
    "\n",
    "    # Creating the tensors\n",
    "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
    "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
    "\n",
    "    self.logger.log_train_opt(\"Adam\")\n",
    "    for epoch in range(tf_epochs):\n",
    "      # Optimization step\n",
    "      loss_value, grads = self.__grad(X_u, u)\n",
    "      self.optimizer.apply_gradients(zip(grads, self.__wrap_training_variables()))\n",
    "      self.logger.log_train_epoch(epoch, loss_value)\n",
    "    \n",
    "    self.logger.log_train_opt(\"LBFGS\")\n",
    "    def loss_and_flat_grad(w):\n",
    "      with tf.GradientTape() as tape:\n",
    "        self.set_weights(w)\n",
    "        loss_value = self.__loss(u, self.u_model(X_u))\n",
    "      grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
    "      grad_flat = []\n",
    "      for g in grad:\n",
    "        grad_flat.append(tf.reshape(g, [-1]))\n",
    "      grad_flat =  tf.concat(grad_flat, 0)\n",
    "      return loss_value, grad_flat\n",
    "    # tfp.optimizer.lbfgs_minimize(\n",
    "    #   loss_and_flat_grad,\n",
    "    #   initial_position=self.get_weights(),\n",
    "    #   num_correction_pairs=nt_config.nCorrection,\n",
    "    #   max_iterations=nt_config.maxIter,\n",
    "    #   f_relative_tolerance=nt_config.tolFun,\n",
    "    #   tolerance=nt_config.tolFun,\n",
    "    #   parallel_iterations=6)\n",
    "    \"\"\"lbfgs(loss_and_flat_grad,\n",
    "      self.get_weights(),\n",
    "      nt_config, Struct(), True,\n",
    "      lambda epoch, loss, is_iter:\n",
    "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\"\"\"\n",
    "\n",
    "    self.logger.log_train_end(tf_epochs + nt_config.maxIter)\n",
    "\n",
    "  def predict(self, X_star):\n",
    "    u_star = self.u_model(X_star)\n",
    "    f_star = self.f_model()\n",
    "    return u_star, f_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters quantum PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size on the solution u\n",
    "N_u = 50\n",
    "# Collocation points size, where we’ll check for f = 0\n",
    "N_f = 10000\n",
    "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
    "\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
    "tf_epochs = 1000\n",
    "tf_optimizer = tf.keras.optimizers.Adam(\n",
    "  learning_rate=0.3,\n",
    "  beta_1=0.99,\n",
    "  epsilon=1e-1)\n",
    "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
    "nt_epochs = 2000\n",
    "nt_config = Struct()\n",
    "nt_config.learningRate = 0.8\n",
    "nt_config.maxIter = nt_epochs\n",
    "nt_config.nCorrection = 50\n",
    "nt_config.tolFun = 1.0 * np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.3.1\n",
      "Eager execution: True\n",
      "GPU-accerelated: False\n",
      "\n",
      "Training started\n",
      "================\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "lambda_layer (Lambda)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 3,021\n",
      "Trainable params: 3,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "—— Starting Adam optimization ——\n",
      "tf_epoch =      0  elapsed = 00:00  loss = 3.0947e-01  error = 7.6310e-01  \n",
      "tf_epoch =     10  elapsed = 00:03  loss = 2.0689e-01  error = 6.1398e-01  \n",
      "tf_epoch =     20  elapsed = 00:05  loss = 2.1323e-01  error = 5.7652e-01  \n",
      "tf_epoch =     30  elapsed = 00:07  loss = 1.8355e-01  error = 5.6060e-01  \n",
      "tf_epoch =     40  elapsed = 00:09  loss = 1.6999e-01  error = 6.1787e-01  \n",
      "tf_epoch =     50  elapsed = 00:11  loss = 1.6646e-01  error = 6.1302e-01  \n",
      "tf_epoch =     60  elapsed = 00:14  loss = 1.6262e-01  error = 6.4430e-01  \n",
      "tf_epoch =     70  elapsed = 00:16  loss = 1.5312e-01  error = 6.2794e-01  \n",
      "tf_epoch =     80  elapsed = 00:18  loss = 1.4697e-01  error = 6.8166e-01  \n",
      "tf_epoch =     90  elapsed = 00:20  loss = 1.4067e-01  error = 6.6494e-01  \n",
      "tf_epoch =    100  elapsed = 00:22  loss = 1.3173e-01  error = 5.5776e-01  \n",
      "tf_epoch =    110  elapsed = 00:24  loss = 1.2036e-01  error = 5.0897e-01  \n",
      "tf_epoch =    120  elapsed = 00:26  loss = 1.1129e-01  error = 5.6262e-01  \n",
      "tf_epoch =    130  elapsed = 00:29  loss = 1.0430e-01  error = 6.2653e-01  \n",
      "tf_epoch =    140  elapsed = 00:31  loss = 1.0744e-01  error = 5.9390e-01  \n",
      "tf_epoch =    150  elapsed = 00:33  loss = 9.2016e-02  error = 5.5151e-01  \n",
      "tf_epoch =    160  elapsed = 00:35  loss = 9.3217e-02  error = 4.9763e-01  \n",
      "tf_epoch =    170  elapsed = 00:37  loss = 9.3349e-02  error = 5.3465e-01  \n",
      "tf_epoch =    180  elapsed = 00:40  loss = 9.0245e-02  error = 5.1546e-01  \n",
      "tf_epoch =    190  elapsed = 00:42  loss = 8.3463e-02  error = 5.0116e-01  \n",
      "tf_epoch =    200  elapsed = 00:44  loss = 8.0769e-02  error = 4.9702e-01  \n",
      "tf_epoch =    210  elapsed = 00:46  loss = 7.9126e-02  error = 4.7474e-01  \n",
      "tf_epoch =    220  elapsed = 00:48  loss = 7.1365e-02  error = 4.6213e-01  \n",
      "tf_epoch =    230  elapsed = 00:51  loss = 6.3862e-02  error = 4.2142e-01  \n",
      "tf_epoch =    240  elapsed = 00:53  loss = 6.3370e-02  error = 4.5044e-01  \n",
      "tf_epoch =    250  elapsed = 00:55  loss = 5.8765e-02  error = 4.2957e-01  \n",
      "tf_epoch =    260  elapsed = 00:57  loss = 5.9814e-02  error = 4.4290e-01  \n",
      "tf_epoch =    270  elapsed = 00:59  loss = 5.7422e-02  error = 4.0346e-01  \n",
      "tf_epoch =    280  elapsed = 01:02  loss = 5.0643e-02  error = 3.6316e-01  \n",
      "tf_epoch =    290  elapsed = 01:06  loss = 5.0285e-02  error = 3.3301e-01  \n",
      "tf_epoch =    300  elapsed = 01:09  loss = 5.5724e-02  error = 3.8863e-01  \n",
      "tf_epoch =    310  elapsed = 01:12  loss = 4.7505e-02  error = 4.5927e-01  \n",
      "tf_epoch =    320  elapsed = 01:14  loss = 6.1127e-02  error = 4.4064e-01  \n",
      "tf_epoch =    330  elapsed = 01:16  loss = 4.5825e-02  error = 4.1632e-01  \n",
      "tf_epoch =    340  elapsed = 01:20  loss = 5.1888e-02  error = 3.9297e-01  \n",
      "tf_epoch =    350  elapsed = 01:22  loss = 5.4171e-02  error = 3.3236e-01  \n",
      "tf_epoch =    360  elapsed = 01:25  loss = 5.8945e-02  error = 5.0681e-01  \n",
      "tf_epoch =    370  elapsed = 01:28  loss = 4.3443e-02  error = 3.1555e-01  \n",
      "tf_epoch =    380  elapsed = 01:31  loss = 4.2228e-02  error = 3.2505e-01  \n",
      "tf_epoch =    390  elapsed = 01:33  loss = 4.6559e-02  error = 3.5618e-01  \n",
      "tf_epoch =    400  elapsed = 01:35  loss = 3.5721e-02  error = 3.3145e-01  \n",
      "tf_epoch =    410  elapsed = 01:37  loss = 3.3378e-02  error = 4.0764e-01  \n",
      "tf_epoch =    420  elapsed = 01:39  loss = 3.2230e-02  error = 4.2463e-01  \n",
      "tf_epoch =    430  elapsed = 01:41  loss = 2.9145e-02  error = 4.1810e-01  \n",
      "tf_epoch =    440  elapsed = 01:44  loss = 3.0469e-02  error = 4.0658e-01  \n",
      "tf_epoch =    450  elapsed = 01:46  loss = 4.5056e-02  error = 6.0053e-01  \n",
      "tf_epoch =    460  elapsed = 01:48  loss = 9.3639e-02  error = 8.0787e-01  \n",
      "tf_epoch =    470  elapsed = 01:50  loss = 5.0367e-02  error = 7.5437e-01  \n",
      "tf_epoch =    480  elapsed = 01:53  loss = 7.0287e-02  error = 4.2400e-01  \n",
      "tf_epoch =    490  elapsed = 01:56  loss = 7.1461e-02  error = 3.4460e-01  \n",
      "tf_epoch =    500  elapsed = 01:58  loss = 4.4876e-02  error = 4.1492e-01  \n",
      "tf_epoch =    510  elapsed = 02:00  loss = 5.2071e-02  error = 3.8144e-01  \n",
      "tf_epoch =    520  elapsed = 02:03  loss = 4.3856e-02  error = 3.2020e-01  \n",
      "tf_epoch =    530  elapsed = 02:05  loss = 4.1299e-02  error = 3.2264e-01  \n",
      "tf_epoch =    540  elapsed = 02:07  loss = 4.6702e-02  error = 3.7241e-01  \n",
      "tf_epoch =    550  elapsed = 02:09  loss = 3.6540e-02  error = 4.0055e-01  \n",
      "tf_epoch =    560  elapsed = 02:11  loss = 3.3228e-02  error = 3.6721e-01  \n",
      "tf_epoch =    570  elapsed = 02:14  loss = 3.0262e-02  error = 3.7202e-01  \n",
      "tf_epoch =    580  elapsed = 02:16  loss = 3.0354e-02  error = 3.8545e-01  \n",
      "tf_epoch =    590  elapsed = 02:18  loss = 2.4921e-02  error = 3.8162e-01  \n",
      "tf_epoch =    600  elapsed = 02:20  loss = 1.9267e-02  error = 3.9932e-01  \n",
      "tf_epoch =    610  elapsed = 02:22  loss = 2.5702e-02  error = 3.9204e-01  \n",
      "tf_epoch =    620  elapsed = 02:24  loss = 1.8657e-02  error = 3.0247e-01  \n",
      "tf_epoch =    630  elapsed = 02:26  loss = 2.0497e-02  error = 1.9948e-01  \n",
      "tf_epoch =    640  elapsed = 02:28  loss = 1.4100e-02  error = 2.2916e-01  \n",
      "tf_epoch =    650  elapsed = 02:31  loss = 1.6370e-02  error = 2.3828e-01  \n",
      "tf_epoch =    660  elapsed = 02:33  loss = 1.5201e-02  error = 2.6741e-01  \n",
      "tf_epoch =    670  elapsed = 02:35  loss = 1.2750e-02  error = 3.3364e-01  \n",
      "tf_epoch =    680  elapsed = 02:37  loss = 1.2034e-02  error = 3.1360e-01  \n",
      "tf_epoch =    690  elapsed = 02:41  loss = 1.2623e-02  error = 2.9511e-01  \n",
      "tf_epoch =    700  elapsed = 02:44  loss = 1.2123e-02  error = 2.8087e-01  \n",
      "tf_epoch =    710  elapsed = 02:48  loss = 9.2948e-03  error = 2.7885e-01  \n",
      "tf_epoch =    720  elapsed = 02:51  loss = 9.0348e-03  error = 2.0623e-01  \n",
      "tf_epoch =    730  elapsed = 02:53  loss = 6.8341e-03  error = 2.6402e-01  \n",
      "tf_epoch =    740  elapsed = 02:55  loss = 8.5831e-03  error = 2.4799e-01  \n",
      "tf_epoch =    750  elapsed = 02:58  loss = 6.8945e-03  error = 1.7965e-01  \n",
      "tf_epoch =    760  elapsed = 03:00  loss = 6.2184e-03  error = 9.8046e-02  \n",
      "tf_epoch =    770  elapsed = 03:02  loss = 6.4842e-03  error = 9.5773e-02  \n",
      "tf_epoch =    780  elapsed = 03:04  loss = 5.3345e-03  error = 9.9178e-02  \n",
      "tf_epoch =    790  elapsed = 03:06  loss = 5.3683e-03  error = 1.2015e-01  \n",
      "tf_epoch =    800  elapsed = 03:09  loss = 4.4308e-03  error = 7.7052e-02  \n",
      "tf_epoch =    810  elapsed = 03:11  loss = 4.4547e-03  error = 8.2568e-02  \n",
      "tf_epoch =    820  elapsed = 03:13  loss = 4.3811e-03  error = 1.0559e-01  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_epoch =    830  elapsed = 03:15  loss = 3.5832e-03  error = 1.0337e-01  \n",
      "tf_epoch =    840  elapsed = 03:17  loss = 3.4662e-03  error = 9.8054e-02  \n",
      "tf_epoch =    850  elapsed = 03:20  loss = 2.8600e-03  error = 1.1950e-01  \n",
      "tf_epoch =    860  elapsed = 03:22  loss = 3.1696e-03  error = 1.0996e-01  \n",
      "tf_epoch =    870  elapsed = 03:25  loss = 2.7296e-03  error = 1.0591e-01  \n",
      "tf_epoch =    880  elapsed = 03:28  loss = 2.4287e-03  error = 1.2388e-01  \n",
      "tf_epoch =    890  elapsed = 03:31  loss = 2.1116e-03  error = 1.0151e-01  \n",
      "tf_epoch =    900  elapsed = 03:33  loss = 2.0983e-03  error = 9.2536e-02  \n",
      "tf_epoch =    910  elapsed = 03:36  loss = 1.8938e-03  error = 1.0394e-01  \n",
      "tf_epoch =    920  elapsed = 03:38  loss = 1.9134e-03  error = 9.5339e-02  \n",
      "tf_epoch =    930  elapsed = 03:40  loss = 1.6517e-03  error = 8.7342e-02  \n",
      "tf_epoch =    940  elapsed = 03:43  loss = 1.5823e-03  error = 6.7931e-02  \n",
      "tf_epoch =    950  elapsed = 03:45  loss = 1.6432e-03  error = 6.9379e-02  \n",
      "tf_epoch =    960  elapsed = 03:48  loss = 1.5059e-03  error = 6.6779e-02  \n",
      "tf_epoch =    970  elapsed = 03:50  loss = 1.2788e-03  error = 5.9746e-02  \n",
      "tf_epoch =    980  elapsed = 03:53  loss = 1.2223e-03  error = 4.8701e-02  \n",
      "tf_epoch =    990  elapsed = 03:55  loss = 1.1859e-03  error = 5.0617e-02  \n",
      "—— Starting LBFGS optimization ——\n",
      "==================\n",
      "Training finished (epoch 3000): duration = 03:57  error = 5.9174e-02  \n"
     ]
    }
   ],
   "source": [
    "# Getting the data\n",
    "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
    "x, t, X, T, Exact_u, X_star, u_star, \\\n",
    "  X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
    "\n",
    "# Creating the model and training\n",
    "logger = Logger(frequency=10)\n",
    "qpinn = QPhysicsInformedNN(layers, tf_optimizer, logger, X_f, ub, lb, nu=0.01/np.pi)\n",
    "def error():\n",
    "  u_pred, _ = qpinn.predict(X_star)\n",
    "  return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "logger.set_error_fn(error)\n",
    "qpinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
    "\n",
    "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
    "u_pred, f_pred = qpinn.predict(X_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 388.543x264.146 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_inf_cont_results(X_star, u_pred.numpy().flatten(), X_u_train, u_train,\n",
    "  Exact_u, X, T, x, t, file = \"qplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "A1Mj-RBCn8MZ",
    "GkimJNtepkKi",
    "dOPzdkKsJzA4",
    "OTxvp1nJGDeb",
    "QGd5zVtoxAqt",
    "bXtJ5GiaxAqw",
    "fGrMDRc3w1ex",
    "rRGW4IW0w1e0"
   ],
   "name": "PINNs for 1D Burgers Equation (TF2.0).ipynb",
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
